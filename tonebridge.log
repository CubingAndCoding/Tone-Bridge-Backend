2025-07-24 21:15:03 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 21:15:03 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 21:15:03 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 21:52:31 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 21:52:31 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 21:52:31 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 21:56:03 - utils.audio_utils - ERROR - Failed to load audio: Error opening <_io.BytesIO object at 0x00000162AA234590>: Format not recognised.
2025-07-24 21:56:03 - services.transcription_service - ERROR - Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000162AA234590>: Format not recognised.
2025-07-24 21:56:03 - routes.api - ERROR - Transcription endpoint error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000162AA234590>: Format not recognised.
2025-07-24 21:56:03 - utils.error_handlers - ERROR - ToneBridge Error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000162AA234590>: Format not recognised.
Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 40, in load_audio
    audio_array, sample_rate = librosa.load(
                               ^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 185, in load
    raise exc
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 175, in load
    y, sr_native = __soundfile_load(path, offset, duration, dtype)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 208, in __soundfile_load
    context = sf.SoundFile(path)
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 1216, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x00000162AA234590>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 76, in transcribe_audio
    audio_array, sample_rate = audio_processor.load_audio(audio_data)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 58, in load_audio
    raise AudioProcessingError(f"Failed to load audio: {str(e)}")
utils.error_handlers.AudioProcessingError: Failed to load audio: Error opening <_io.BytesIO object at 0x00000162AA234590>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\routes\api.py", line 73, in transcribe_audio
    transcription_result = transcription_service.transcribe_audio(audio_data, audio_format)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 91, in transcribe_audio
    raise AudioProcessingError(f"Transcription failed: {str(e)}")
utils.error_handlers.AudioProcessingError: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000162AA234590>: Format not recognised.
2025-07-24 22:01:03 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:01:03 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:01:03 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:01:09 - utils.audio_utils - ERROR - Failed to load audio: Error opening <_io.BytesIO object at 0x000001D0C47E48B0>: Format not recognised.
2025-07-24 22:01:09 - services.transcription_service - ERROR - Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x000001D0C47E48B0>: Format not recognised.
2025-07-24 22:01:09 - routes.api - ERROR - Transcription endpoint error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x000001D0C47E48B0>: Format not recognised.
2025-07-24 22:01:09 - utils.error_handlers - ERROR - ToneBridge Error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x000001D0C47E48B0>: Format not recognised.
Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 40, in load_audio
    audio_array, sample_rate = librosa.load(
                               ^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 185, in load
    raise exc
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 175, in load
    y, sr_native = __soundfile_load(path, offset, duration, dtype)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 208, in __soundfile_load
    context = sf.SoundFile(path)
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 1216, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x000001D0C47E48B0>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 76, in transcribe_audio
    audio_array, sample_rate = audio_processor.load_audio(audio_data)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 58, in load_audio
    raise AudioProcessingError(f"Failed to load audio: {str(e)}")
utils.error_handlers.AudioProcessingError: Failed to load audio: Error opening <_io.BytesIO object at 0x000001D0C47E48B0>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\routes\api.py", line 73, in transcribe_audio
    transcription_result = transcription_service.transcribe_audio(audio_data, audio_format)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 91, in transcribe_audio
    raise AudioProcessingError(f"Transcription failed: {str(e)}")
utils.error_handlers.AudioProcessingError: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x000001D0C47E48B0>: Format not recognised.
2025-07-24 22:06:27 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:06:27 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:06:27 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:06:32 - utils.audio_utils - ERROR - Failed to load audio: Expecting value: line 1 column 1 (char 0)
2025-07-24 22:06:32 - services.transcription_service - ERROR - Transcription failed: Failed to load audio: Expecting value: line 1 column 1 (char 0)
2025-07-24 22:06:32 - routes.api - ERROR - Transcription endpoint error: Transcription failed: Failed to load audio: Expecting value: line 1 column 1 (char 0)
2025-07-24 22:06:32 - utils.error_handlers - ERROR - ToneBridge Error: Transcription failed: Failed to load audio: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 41, in load_audio
    audio = AudioSegment.from_file(io.BytesIO(audio_data), format='webm')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\pydub\audio_segment.py", line 728, in from_file
    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\pydub\utils.py", line 279, in mediainfo_json
    info = json.loads(output)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 76, in transcribe_audio
    audio_array, sample_rate = audio_processor.load_audio(audio_data, format=audio_format)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 69, in load_audio
    raise AudioProcessingError(f"Failed to load audio: {str(e)}")
utils.error_handlers.AudioProcessingError: Failed to load audio: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\routes\api.py", line 73, in transcribe_audio
    transcription_result = transcription_service.transcribe_audio(audio_data, audio_format)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 91, in transcribe_audio
    raise AudioProcessingError(f"Transcription failed: {str(e)}")
utils.error_handlers.AudioProcessingError: Transcription failed: Failed to load audio: Expecting value: line 1 column 1 (char 0)
2025-07-24 22:18:17 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:18:17 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:18:17 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:18:26 - routes.api - INFO - Audio data decoded successfully: 27209 bytes, format: webm
2025-07-24 22:18:26 - utils.audio_utils - INFO - Loading audio: 27209 bytes, format: webm
2025-07-24 22:18:26 - utils.audio_utils - INFO - Converting webm to wav using pydub...
2025-07-24 22:18:26 - utils.audio_utils - ERROR - Webm conversion failed: Expecting value: line 1 column 1 (char 0)
2025-07-24 22:18:26 - utils.audio_utils - INFO - Trying direct loading as fallback...
2025-07-24 22:18:28 - utils.audio_utils - ERROR - Failed to load audio: Error opening <_io.BytesIO object at 0x00000207C74F8400>: Format not recognised.
2025-07-24 22:18:28 - utils.audio_utils - ERROR - Audio data length: 27209
2025-07-24 22:18:28 - utils.audio_utils - ERROR - Audio format: webm
2025-07-24 22:18:28 - services.transcription_service - ERROR - Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000207C74F8400>: Format not recognised.
2025-07-24 22:18:28 - routes.api - ERROR - Transcription endpoint error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000207C74F8400>: Format not recognised.
2025-07-24 22:18:28 - utils.error_handlers - ERROR - ToneBridge Error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000207C74F8400>: Format not recognised.
Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 48, in load_audio
    audio = AudioSegment.from_file(io.BytesIO(audio_data), format='webm')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\pydub\audio_segment.py", line 728, in from_file
    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\pydub\utils.py", line 279, in mediainfo_json
    info = json.loads(output)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 65, in load_audio
    audio_array, sample_rate = librosa.load(
                               ^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 185, in load
    raise exc
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 175, in load
    y, sr_native = __soundfile_load(path, offset, duration, dtype)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 208, in __soundfile_load
    context = sf.SoundFile(path)
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 1216, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x00000207C74F8400>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 76, in transcribe_audio
    audio_array, sample_rate = audio_processor.load_audio(audio_data, format=audio_format)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 91, in load_audio
    raise AudioProcessingError(f"Failed to load audio: {str(e)}")
utils.error_handlers.AudioProcessingError: Failed to load audio: Error opening <_io.BytesIO object at 0x00000207C74F8400>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\routes\api.py", line 82, in transcribe_audio
    transcription_result = transcription_service.transcribe_audio(audio_data, audio_format)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 91, in transcribe_audio
    raise AudioProcessingError(f"Transcription failed: {str(e)}")
utils.error_handlers.AudioProcessingError: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000207C74F8400>: Format not recognised.
2025-07-24 22:23:17 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:23:17 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:23:17 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:23:27 - routes.api - INFO - Audio data decoded successfully: 31073 bytes, format: webm
2025-07-24 22:23:27 - utils.audio_utils - INFO - Loading audio: 31073 bytes, format: webm
2025-07-24 22:23:27 - utils.audio_utils - INFO - Saved received audio to debug_received.webm
2025-07-24 22:23:27 - utils.audio_utils - INFO - Converting webm to wav using pydub...
2025-07-24 22:23:27 - utils.audio_utils - ERROR - Webm conversion failed: Expecting value: line 1 column 1 (char 0)
2025-07-24 22:23:27 - utils.audio_utils - INFO - Trying direct loading as fallback...
2025-07-24 22:23:29 - utils.audio_utils - ERROR - Failed to load audio: Error opening <_io.BytesIO object at 0x00000165DAD1C5E0>: Format not recognised.
2025-07-24 22:23:29 - utils.audio_utils - ERROR - Audio data length: 31073
2025-07-24 22:23:29 - utils.audio_utils - ERROR - Audio format: webm
2025-07-24 22:23:29 - services.transcription_service - ERROR - Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000165DAD1C5E0>: Format not recognised.
2025-07-24 22:23:29 - routes.api - ERROR - Transcription endpoint error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000165DAD1C5E0>: Format not recognised.
2025-07-24 22:23:29 - utils.error_handlers - ERROR - ToneBridge Error: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000165DAD1C5E0>: Format not recognised.
Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 55, in load_audio
    audio = AudioSegment.from_file(io.BytesIO(audio_data), format='webm')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\pydub\audio_segment.py", line 728, in from_file
    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\pydub\utils.py", line 279, in mediainfo_json
    info = json.loads(output)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 72, in load_audio
    audio_array, sample_rate = librosa.load(
                               ^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 185, in load
    raise exc
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 175, in load
    y, sr_native = __soundfile_load(path, offset, duration, dtype)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\librosa\core\audio.py", line 208, in __soundfile_load
    context = sf.SoundFile(path)
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\soundfile.py", line 1216, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x00000165DAD1C5E0>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 76, in transcribe_audio
    audio_array, sample_rate = audio_processor.load_audio(audio_data, format=audio_format)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\utils\audio_utils.py", line 98, in load_audio
    raise AudioProcessingError(f"Failed to load audio: {str(e)}")
utils.error_handlers.AudioProcessingError: Failed to load audio: Error opening <_io.BytesIO object at 0x00000165DAD1C5E0>: Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\routes\api.py", line 82, in transcribe_audio
    transcription_result = transcription_service.transcribe_audio(audio_data, audio_format)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 91, in transcribe_audio
    raise AudioProcessingError(f"Transcription failed: {str(e)}")
utils.error_handlers.AudioProcessingError: Transcription failed: Failed to load audio: Error opening <_io.BytesIO object at 0x00000165DAD1C5E0>: Format not recognised.
2025-07-24 22:29:36 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:29:36 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:29:36 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:29:41 - routes.api - INFO - Audio data decoded successfully: 30107 bytes, format: webm
2025-07-24 22:29:41 - utils.audio_utils - INFO - Loading audio: 30107 bytes, format: webm
2025-07-24 22:29:41 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:29:41 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp11btw90r.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp11btw90r.wav
2025-07-24 22:29:41 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:29:55 - utils.audio_utils - INFO - Audio loaded successfully: 29760 samples, 16000Hz
2025-07-24 22:29:58 - utils.audio_utils - INFO - Audio preprocessed: 28672 samples
2025-07-24 22:29:59 - services.transcription_service - ERROR - Sphinx recognition failed: missing PocketSphinx module: ensure that PocketSphinx is set up correctly.
2025-07-24 22:29:59 - services.transcription_service - ERROR - Speech recognition failed: All speech recognition methods failed
2025-07-24 22:29:59 - services.transcription_service - ERROR - Transcription failed: Speech recognition failed: All speech recognition methods failed
2025-07-24 22:29:59 - routes.api - ERROR - Transcription endpoint error: Transcription failed: Speech recognition failed: All speech recognition methods failed
2025-07-24 22:29:59 - utils.error_handlers - ERROR - ToneBridge Error: Transcription failed: Speech recognition failed: All speech recognition methods failed
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\speech_recognition\__init__.py", line 600, in recognize_sphinx
    from pocketsphinx import pocketsphinx, Jsgf, FsgModel
ModuleNotFoundError: No module named 'pocketsphinx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 142, in _transcribe_with_speech_recognition
    text = self.recognizer.recognize_sphinx(audio)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\speech_recognition\__init__.py", line 603, in recognize_sphinx
    raise RequestError("missing PocketSphinx module: ensure that PocketSphinx is set up correctly.")
speech_recognition.exceptions.RequestError: missing PocketSphinx module: ensure that PocketSphinx is set up correctly.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 147, in _transcribe_with_speech_recognition
    raise AudioProcessingError("All speech recognition methods failed")
utils.error_handlers.AudioProcessingError: All speech recognition methods failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 84, in transcribe_audio
    result = self._transcribe_with_speech_recognition(audio_data, audio_format)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 158, in _transcribe_with_speech_recognition
    raise AudioProcessingError(f"Speech recognition failed: {str(e)}")
utils.error_handlers.AudioProcessingError: Speech recognition failed: All speech recognition methods failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\routes\api.py", line 82, in transcribe_audio
    transcription_result = transcription_service.transcribe_audio(audio_data, audio_format)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\transcription_service.py", line 91, in transcribe_audio
    raise AudioProcessingError(f"Transcription failed: {str(e)}")
utils.error_handlers.AudioProcessingError: Transcription failed: Speech recognition failed: All speech recognition methods failed
2025-07-24 22:32:14 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:32:14 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:32:14 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:32:19 - routes.api - INFO - Audio data decoded successfully: 28175 bytes, format: webm
2025-07-24 22:32:19 - utils.audio_utils - INFO - Loading audio: 28175 bytes, format: webm
2025-07-24 22:32:19 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:32:19 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp6s926v5u.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp6s926v5u.wav
2025-07-24 22:32:20 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:32:22 - utils.audio_utils - INFO - Audio loaded successfully: 27840 samples, 16000Hz
2025-07-24 22:32:22 - utils.audio_utils - INFO - Audio preprocessed: 17920 samples
2025-07-24 22:32:24 - services.transcription_service - INFO - Used Sphinx recognition
2025-07-24 22:32:24 - services.transcription_service - INFO - Transcription completed: 0 characters
2025-07-24 22:32:24 - routes.api - INFO - API Request - Duration: 4.039s | Request: {'audio_length': 28175, 'format': 'webm', 'include_emotion': True} | Response: {'transcript': '', 'confidence': 0.5, 'model': 'speech_recognition', 'language': 'en'}
2025-07-24 22:32:44 - routes.api - INFO - Audio data decoded successfully: 40733 bytes, format: webm
2025-07-24 22:32:44 - utils.audio_utils - INFO - Loading audio: 40733 bytes, format: webm
2025-07-24 22:32:44 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:32:44 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpjj396lqg.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpjj396lqg.wav
2025-07-24 22:32:44 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:32:44 - utils.audio_utils - INFO - Audio loaded successfully: 40320 samples, 16000Hz
2025-07-24 22:32:44 - utils.audio_utils - INFO - Audio preprocessed: 33280 samples
2025-07-24 22:32:45 - services.transcription_service - INFO - Used Sphinx recognition
2025-07-24 22:32:45 - services.transcription_service - INFO - Transcription completed: 0 characters
2025-07-24 22:32:45 - routes.api - INFO - API Request - Duration: 1.138s | Request: {'audio_length': 40733, 'format': 'webm', 'include_emotion': True} | Response: {'transcript': '', 'confidence': 0.5, 'model': 'speech_recognition', 'language': 'en'}
2025-07-24 22:33:49 - routes.api - INFO - Audio data decoded successfully: 52325 bytes, format: webm
2025-07-24 22:33:49 - utils.audio_utils - INFO - Loading audio: 52325 bytes, format: webm
2025-07-24 22:33:49 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:33:49 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp0w58_ps1.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp0w58_ps1.wav
2025-07-24 22:33:49 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:33:49 - utils.audio_utils - INFO - Audio loaded successfully: 51840 samples, 16000Hz
2025-07-24 22:33:49 - utils.audio_utils - INFO - Audio preprocessed: 29696 samples
2025-07-24 22:33:50 - services.transcription_service - INFO - Used Sphinx recognition
2025-07-24 22:33:50 - services.transcription_service - INFO - Transcription completed: 0 characters
2025-07-24 22:33:50 - routes.api - INFO - API Request - Duration: 1.298s | Request: {'audio_length': 52325, 'format': 'webm', 'include_emotion': True} | Response: {'transcript': '', 'confidence': 0.5, 'model': 'speech_recognition', 'language': 'en'}
2025-07-24 22:34:36 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:34:36 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:34:36 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:34:45 - routes.api - INFO - Audio data decoded successfully: 48461 bytes, format: webm
2025-07-24 22:34:45 - utils.audio_utils - INFO - Loading audio: 48461 bytes, format: webm
2025-07-24 22:34:45 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:34:45 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpdelue4vz.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpdelue4vz.wav
2025-07-24 22:34:45 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:34:47 - utils.audio_utils - INFO - Audio loaded successfully: 48000 samples, 16000Hz
2025-07-24 22:34:48 - utils.audio_utils - INFO - Audio preprocessed: 36352 samples
2025-07-24 22:34:49 - services.transcription_service - INFO - Used Sphinx recognition
2025-07-24 22:34:49 - services.transcription_service - INFO - Transcription completed: 0 characters
2025-07-24 22:34:49 - routes.api - INFO - API Request - Duration: 3.915s | Request: {'audio_length': 48461, 'format': 'webm', 'include_emotion': True} | Response: {'transcript': '', 'confidence': 0.5, 'model': 'speech_recognition', 'language': 'en'}
2025-07-24 22:36:23 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: False
2025-07-24 22:36:23 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:36:23 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:36:23 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:36:33 - routes.api - INFO - Audio data decoded successfully: 64883 bytes, format: webm
2025-07-24 22:36:33 - utils.audio_utils - INFO - Loading audio: 64883 bytes, format: webm
2025-07-24 22:36:33 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:36:33 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpht0v6sec.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpht0v6sec.wav
2025-07-24 22:36:33 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:36:36 - utils.audio_utils - INFO - Audio loaded successfully: 64320 samples, 16000Hz
2025-07-24 22:36:36 - utils.audio_utils - INFO - Audio preprocessed: 42496 samples
2025-07-24 22:36:36 - services.transcription_service - INFO - Using speech_recognition fallback
2025-07-24 22:36:37 - services.transcription_service - INFO - Used Sphinx recognition
2025-07-24 22:36:37 - services.transcription_service - INFO - Transcription completed: '' (0 characters)
2025-07-24 22:36:37 - services.transcription_service - INFO - Confidence: 0.5
2025-07-24 22:36:37 - services.transcription_service - INFO - Model used: speech_recognition
2025-07-24 22:36:37 - routes.api - INFO - API Request - Duration: 4.072s | Request: {'audio_length': 64883, 'format': 'webm', 'include_emotion': True} | Response: {'transcript': '', 'confidence': 0.5, 'model': 'speech_recognition', 'language': 'en'}
2025-07-24 22:39:55 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: False
2025-07-24 22:39:55 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:39:55 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:39:55 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:40:04 - routes.api - INFO - Audio data decoded successfully: 49427 bytes, format: webm
2025-07-24 22:40:04 - utils.audio_utils - INFO - Loading audio: 49427 bytes, format: webm
2025-07-24 22:40:04 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:40:04 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp5zomef8c.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp5zomef8c.wav
2025-07-24 22:40:04 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:40:07 - utils.audio_utils - INFO - Audio loaded successfully: 48960 samples, 16000Hz
2025-07-24 22:40:07 - utils.audio_utils - INFO - Audio preprocessed: 32768 samples
2025-07-24 22:40:07 - services.transcription_service - INFO - Using speech_recognition fallback
2025-07-24 22:40:08 - services.transcription_service - INFO - Used Sphinx recognition
2025-07-24 22:40:08 - services.transcription_service - INFO - Transcription completed: '' (0 characters)
2025-07-24 22:40:08 - services.transcription_service - INFO - Confidence: 0.5
2025-07-24 22:40:08 - services.transcription_service - INFO - Model used: speech_recognition
2025-07-24 22:40:08 - routes.api - INFO - API Request - Duration: 4.277s | Request: {'audio_length': 49427, 'format': 'webm', 'include_emotion': True} | Response: {'transcript': '', 'confidence': 0.5, 'model': 'speech_recognition', 'language': 'en'}
2025-07-24 22:43:37 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: False
2025-07-24 22:43:37 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:43:37 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:43:37 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:44:39 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: False
2025-07-24 22:44:39 - services.transcription_service - INFO - PyTorch/Transformers not available. Using speech_recognition library only.
2025-07-24 22:44:39 - services.emotion_service - INFO - PyTorch/Transformers not available. Using rule-based emotion detection.
2025-07-24 22:44:39 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:50:34 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 22:50:34 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 22:50:34 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 22:50:34 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 22:50:34 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 22:51:37 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 22:51:37 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 22:51:37 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 22:51:38 - services.emotion_service - ERROR - Failed to initialize emotion models: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-07-24 22:51:38 - services.emotion_service - INFO - Falling back to rule-based emotion detection
2025-07-24 22:51:38 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:51:54 - routes.api - INFO - Audio data decoded successfully: 29141 bytes, format: webm
2025-07-24 22:51:54 - utils.audio_utils - INFO - Loading audio: 29141 bytes, format: webm
2025-07-24 22:51:54 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:51:54 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp2f_yxs5_.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp2f_yxs5_.wav
2025-07-24 22:51:54 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:51:56 - utils.audio_utils - INFO - Audio loaded successfully: 28800 samples, 16000Hz
2025-07-24 22:51:56 - utils.audio_utils - INFO - Audio preprocessed: 22016 samples
2025-07-24 22:51:56 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:51:57 - services.transcription_service - INFO - Transcription completed: 'Testing.' (8 characters)
2025-07-24 22:51:57 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:51:57 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:51:57 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:52:05 - routes.api - INFO - Audio data decoded successfully: 28175 bytes, format: webm
2025-07-24 22:52:05 - utils.audio_utils - INFO - Loading audio: 28175 bytes, format: webm
2025-07-24 22:52:05 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:52:05 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpz2pw8cra.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpz2pw8cra.wav
2025-07-24 22:52:05 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:52:05 - utils.audio_utils - INFO - Audio loaded successfully: 27840 samples, 16000Hz
2025-07-24 22:52:05 - utils.audio_utils - INFO - Audio preprocessed: 19456 samples
2025-07-24 22:52:05 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:52:06 - services.transcription_service - INFO - Transcription completed: 'Hey guys, how's it going?' (25 characters)
2025-07-24 22:52:06 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:52:06 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:52:06 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:52:16 - routes.api - INFO - Audio data decoded successfully: 29141 bytes, format: webm
2025-07-24 22:52:16 - utils.audio_utils - INFO - Loading audio: 29141 bytes, format: webm
2025-07-24 22:52:16 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:52:16 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpmt0b33e8.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpmt0b33e8.wav
2025-07-24 22:52:16 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:52:16 - utils.audio_utils - INFO - Audio loaded successfully: 28800 samples, 16000Hz
2025-07-24 22:52:16 - utils.audio_utils - INFO - Audio preprocessed: 28160 samples
2025-07-24 22:52:16 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:52:17 - services.transcription_service - INFO - Transcription completed: 'I'm so excited for this.' (24 characters)
2025-07-24 22:52:17 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:52:17 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:52:17 - services.emotion_service - INFO - Rule-based emotion detected: happy (confidence: 0.200)
2025-07-24 22:52:36 - routes.api - INFO - Audio data decoded successfully: 40733 bytes, format: webm
2025-07-24 22:52:36 - utils.audio_utils - INFO - Loading audio: 40733 bytes, format: webm
2025-07-24 22:52:36 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:52:36 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp5_lv84ln.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp5_lv84ln.wav
2025-07-24 22:52:37 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:52:37 - utils.audio_utils - INFO - Audio loaded successfully: 40320 samples, 16000Hz
2025-07-24 22:52:37 - utils.audio_utils - INFO - Audio preprocessed: 36864 samples
2025-07-24 22:52:37 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:52:37 - services.transcription_service - INFO - Transcription completed: 'Whoa, what the heck does that have?' (35 characters)
2025-07-24 22:52:37 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:52:37 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:52:37 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:52:44 - routes.api - INFO - Audio data decoded successfully: 35903 bytes, format: webm
2025-07-24 22:52:44 - utils.audio_utils - INFO - Loading audio: 35903 bytes, format: webm
2025-07-24 22:52:44 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:52:44 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpnkt1cwwr.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpnkt1cwwr.wav
2025-07-24 22:52:44 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:52:44 - utils.audio_utils - INFO - Audio loaded successfully: 35520 samples, 16000Hz
2025-07-24 22:52:44 - utils.audio_utils - INFO - Audio preprocessed: 30720 samples
2025-07-24 22:52:44 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:52:45 - services.transcription_service - INFO - Transcription completed: 'Whoa what the heck just happened' (32 characters)
2025-07-24 22:52:45 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:52:45 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:52:45 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:53:48 - routes.api - INFO - Audio data decoded successfully: 62951 bytes, format: webm
2025-07-24 22:53:48 - utils.audio_utils - INFO - Loading audio: 62951 bytes, format: webm
2025-07-24 22:53:48 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:53:48 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpot8qvanx.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpot8qvanx.wav
2025-07-24 22:53:48 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:53:48 - utils.audio_utils - INFO - Audio loaded successfully: 62400 samples, 16000Hz
2025-07-24 22:53:48 - utils.audio_utils - INFO - Audio preprocessed: 22016 samples
2025-07-24 22:53:48 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:53:49 - services.transcription_service - INFO - Transcription completed: 'Surprise!' (9 characters)
2025-07-24 22:53:49 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:53:49 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:53:49 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:53:57 - routes.api - INFO - Audio data decoded successfully: 58121 bytes, format: webm
2025-07-24 22:53:57 - utils.audio_utils - INFO - Loading audio: 58121 bytes, format: webm
2025-07-24 22:53:57 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:53:57 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpoo1g3nr2.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpoo1g3nr2.wav
2025-07-24 22:53:57 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:53:57 - utils.audio_utils - INFO - Audio loaded successfully: 57600 samples, 16000Hz
2025-07-24 22:53:57 - utils.audio_utils - INFO - Audio preprocessed: 37376 samples
2025-07-24 22:53:57 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:53:58 - services.transcription_service - INFO - Transcription completed: 'Oh, is that really true?' (24 characters)
2025-07-24 22:53:58 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:53:58 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:53:58 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:54:14 - routes.api - INFO - Audio data decoded successfully: 82271 bytes, format: webm
2025-07-24 22:54:14 - utils.audio_utils - INFO - Loading audio: 82271 bytes, format: webm
2025-07-24 22:54:14 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:54:14 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpz03i0l7o.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpz03i0l7o.wav
2025-07-24 22:54:14 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:54:14 - utils.audio_utils - INFO - Audio loaded successfully: 81600 samples, 16000Hz
2025-07-24 22:54:14 - utils.audio_utils - INFO - Audio preprocessed: 35328 samples
2025-07-24 22:54:14 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:54:15 - services.transcription_service - INFO - Transcription completed: 'Hello? Can you see me?' (22 characters)
2025-07-24 22:54:15 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:54:15 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:54:15 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:54:23 - routes.api - INFO - Audio data decoded successfully: 33005 bytes, format: webm
2025-07-24 22:54:23 - utils.audio_utils - INFO - Loading audio: 33005 bytes, format: webm
2025-07-24 22:54:23 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:54:23 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp8u3gpwtx.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp8u3gpwtx.wav
2025-07-24 22:54:23 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:54:23 - utils.audio_utils - INFO - Audio loaded successfully: 32640 samples, 16000Hz
2025-07-24 22:54:23 - utils.audio_utils - INFO - Audio preprocessed: 29184 samples
2025-07-24 22:54:23 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:54:23 - services.transcription_service - INFO - Transcription completed: 'Are you kidding me?' (19 characters)
2025-07-24 22:54:23 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:54:23 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:54:23 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:54:48 - routes.api - INFO - Audio data decoded successfully: 106421 bytes, format: webm
2025-07-24 22:54:48 - utils.audio_utils - INFO - Loading audio: 106421 bytes, format: webm
2025-07-24 22:54:48 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:54:48 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp0e7jrjtu.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp0e7jrjtu.wav
2025-07-24 22:54:48 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:54:48 - utils.audio_utils - INFO - Audio loaded successfully: 105600 samples, 16000Hz
2025-07-24 22:54:48 - utils.audio_utils - INFO - Audio preprocessed: 99328 samples
2025-07-24 22:54:48 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:54:49 - services.transcription_service - INFO - Transcription completed: 'Happy birthday!' (15 characters)
2025-07-24 22:54:49 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:54:49 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:54:49 - services.emotion_service - INFO - Rule-based emotion detected: happy (confidence: 0.500)
2025-07-24 22:55:11 - routes.api - INFO - Audio data decoded successfully: 70679 bytes, format: webm
2025-07-24 22:55:11 - utils.audio_utils - INFO - Loading audio: 70679 bytes, format: webm
2025-07-24 22:55:11 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:55:11 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp1c19n_pb.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp1c19n_pb.wav
2025-07-24 22:55:11 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:55:11 - utils.audio_utils - INFO - Audio loaded successfully: 70080 samples, 16000Hz
2025-07-24 22:55:11 - utils.audio_utils - INFO - Audio preprocessed: 40448 samples
2025-07-24 22:55:11 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:55:12 - services.transcription_service - INFO - Transcription completed: 'My head is hurting' (18 characters)
2025-07-24 22:55:12 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:55:12 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:55:12 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:55:26 - routes.api - INFO - Audio data decoded successfully: 57155 bytes, format: webm
2025-07-24 22:55:26 - utils.audio_utils - INFO - Loading audio: 57155 bytes, format: webm
2025-07-24 22:55:26 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:55:26 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp_av1zj70.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp_av1zj70.wav
2025-07-24 22:55:26 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:55:26 - utils.audio_utils - INFO - Audio loaded successfully: 56640 samples, 16000Hz
2025-07-24 22:55:26 - utils.audio_utils - INFO - Audio preprocessed: 52736 samples
2025-07-24 22:55:26 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:55:27 - services.transcription_service - INFO - Transcription completed: 'Yes I did! Yeah!' (16 characters)
2025-07-24 22:55:27 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:55:27 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:55:27 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:55:41 - routes.api - INFO - Audio data decoded successfully: 56189 bytes, format: webm
2025-07-24 22:55:41 - utils.audio_utils - INFO - Loading audio: 56189 bytes, format: webm
2025-07-24 22:55:41 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:55:41 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp12cemzhh.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp12cemzhh.wav
2025-07-24 22:55:41 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:55:41 - utils.audio_utils - INFO - Audio loaded successfully: 55680 samples, 16000Hz
2025-07-24 22:55:41 - utils.audio_utils - INFO - Audio preprocessed: 43520 samples
2025-07-24 22:55:41 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:55:42 - services.transcription_service - INFO - Transcription completed: 'Happy anniversary!' (18 characters)
2025-07-24 22:55:42 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:55:42 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:55:42 - services.emotion_service - INFO - Rule-based emotion detected: happy (confidence: 0.500)
2025-07-24 22:56:09 - routes.api - INFO - Audio data decoded successfully: 52325 bytes, format: webm
2025-07-24 22:56:09 - utils.audio_utils - INFO - Loading audio: 52325 bytes, format: webm
2025-07-24 22:56:09 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:56:09 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpcw_57u4v.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpcw_57u4v.wav
2025-07-24 22:56:09 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:56:09 - utils.audio_utils - INFO - Audio loaded successfully: 51840 samples, 16000Hz
2025-07-24 22:56:09 - utils.audio_utils - INFO - Audio preprocessed: 36864 samples
2025-07-24 22:56:09 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:56:10 - services.transcription_service - INFO - Transcription completed: 'I have my water in your doing.' (30 characters)
2025-07-24 22:56:10 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:56:10 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:56:10 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:56:22 - routes.api - INFO - Audio data decoded successfully: 50393 bytes, format: webm
2025-07-24 22:56:22 - utils.audio_utils - INFO - Loading audio: 50393 bytes, format: webm
2025-07-24 22:56:22 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:56:22 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpp5efu_fy.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpp5efu_fy.wav
2025-07-24 22:56:22 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:56:22 - utils.audio_utils - INFO - Audio loaded successfully: 49920 samples, 16000Hz
2025-07-24 22:56:22 - utils.audio_utils - INFO - Audio preprocessed: 49920 samples
2025-07-24 22:56:22 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:56:23 - services.transcription_service - INFO - Transcription completed: 'I'm so bad!' (11 characters)
2025-07-24 22:56:23 - services.transcription_service - INFO - Confidence: 0.0
2025-07-24 22:56:23 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:56:23 - services.emotion_service - INFO - Rule-based emotion detected: neutral (confidence: 0.500)
2025-07-24 22:58:51 - routes.api - INFO - Audio data decoded successfully: 11753 bytes, format: webm
2025-07-24 22:58:51 - utils.audio_utils - INFO - Loading audio: 11753 bytes, format: webm
2025-07-24 22:58:51 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:58:51 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp0vd791zi.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp0vd791zi.wav
2025-07-24 22:58:51 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:58:51 - utils.audio_utils - INFO - Audio loaded successfully: 11520 samples, 16000Hz
2025-07-24 22:58:51 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-07-24 22:58:51 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:00 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 22:59:00 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 22:59:00 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 22:59:00 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 22:59:00 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 22:59:02 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 22:59:02 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 22:59:02 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 22:59:02 - services.emotion_service - ERROR - Failed to initialize emotion models: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-07-24 22:59:02 - services.emotion_service - INFO - Falling back to rule-based emotion detection
2025-07-24 22:59:02 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 22:59:08 - routes.api - INFO - Audio data decoded successfully: 26243 bytes, format: webm
2025-07-24 22:59:08 - utils.audio_utils - INFO - Loading audio: 26243 bytes, format: webm
2025-07-24 22:59:08 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:59:08 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpn1nfdfdx.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpn1nfdfdx.wav
2025-07-24 22:59:08 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:59:11 - utils.audio_utils - INFO - Audio loaded successfully: 25920 samples, 16000Hz
2025-07-24 22:59:11 - utils.audio_utils - INFO - Audio preprocessed: 18432 samples
2025-07-24 22:59:11 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:12 - services.transcription_service - INFO - Transcription completed: 'I'm happy.' (10 characters)
2025-07-24 22:59:12 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 22:59:12 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:59:12 - services.emotion_service - INFO - Enhanced rule-based emotion detected: happy (confidence: 0.300)
2025-07-24 22:59:18 - routes.api - INFO - Audio data decoded successfully: 32039 bytes, format: webm
2025-07-24 22:59:18 - utils.audio_utils - INFO - Loading audio: 32039 bytes, format: webm
2025-07-24 22:59:18 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:59:18 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpznim_n02.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpznim_n02.wav
2025-07-24 22:59:18 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:59:18 - utils.audio_utils - INFO - Audio loaded successfully: 31680 samples, 16000Hz
2025-07-24 22:59:18 - utils.audio_utils - INFO - Audio preprocessed: 27648 samples
2025-07-24 22:59:18 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:19 - services.transcription_service - INFO - Transcription completed: 'This is terrible.' (17 characters)
2025-07-24 22:59:19 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-07-24 22:59:19 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:59:19 - services.emotion_service - INFO - Enhanced rule-based emotion detected: sad (confidence: 0.300)
2025-07-24 22:59:25 - routes.api - INFO - Audio data decoded successfully: 30107 bytes, format: webm
2025-07-24 22:59:25 - utils.audio_utils - INFO - Loading audio: 30107 bytes, format: webm
2025-07-24 22:59:25 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:59:25 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp_dl4li02.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp_dl4li02.wav
2025-07-24 22:59:26 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:59:26 - utils.audio_utils - INFO - Audio loaded successfully: 29760 samples, 16000Hz
2025-07-24 22:59:26 - utils.audio_utils - INFO - Audio preprocessed: 22528 samples
2025-07-24 22:59:26 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:26 - services.transcription_service - INFO - Transcription completed: 'I'm so angry' (12 characters)
2025-07-24 22:59:26 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-07-24 22:59:26 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:59:26 - services.emotion_service - INFO - Enhanced rule-based emotion detected: angry (confidence: 0.333)
2025-07-24 22:59:33 - routes.api - INFO - Audio data decoded successfully: 36869 bytes, format: webm
2025-07-24 22:59:33 - utils.audio_utils - INFO - Loading audio: 36869 bytes, format: webm
2025-07-24 22:59:33 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:59:33 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpgxgbh8ra.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpgxgbh8ra.wav
2025-07-24 22:59:33 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:59:33 - utils.audio_utils - INFO - Audio loaded successfully: 36480 samples, 16000Hz
2025-07-24 22:59:33 - utils.audio_utils - INFO - Audio preprocessed: 22528 samples
2025-07-24 22:59:33 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:34 - services.transcription_service - INFO - Transcription completed: 'Hello world!' (12 characters)
2025-07-24 22:59:34 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 22:59:34 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:59:34 - services.emotion_service - INFO - Enhanced rule-based emotion detected: neutral (confidence: 0.400)
2025-07-24 22:59:38 - routes.api - INFO - Audio data decoded successfully: 23345 bytes, format: webm
2025-07-24 22:59:38 - utils.audio_utils - INFO - Loading audio: 23345 bytes, format: webm
2025-07-24 22:59:38 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:59:38 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmptury1jrh.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmptury1jrh.wav
2025-07-24 22:59:38 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:59:38 - utils.audio_utils - INFO - Audio loaded successfully: 23040 samples, 16000Hz
2025-07-24 22:59:38 - utils.audio_utils - INFO - Audio preprocessed: 17920 samples
2025-07-24 22:59:38 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:39 - services.transcription_service - INFO - Transcription completed: 'Hello world!' (12 characters)
2025-07-24 22:59:39 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 22:59:39 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:59:39 - services.emotion_service - INFO - Enhanced rule-based emotion detected: neutral (confidence: 0.400)
2025-07-24 22:59:45 - routes.api - INFO - Audio data decoded successfully: 31073 bytes, format: webm
2025-07-24 22:59:45 - utils.audio_utils - INFO - Loading audio: 31073 bytes, format: webm
2025-07-24 22:59:45 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:59:45 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpsbhkfg7s.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpsbhkfg7s.wav
2025-07-24 22:59:45 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:59:45 - utils.audio_utils - INFO - Audio loaded successfully: 30720 samples, 16000Hz
2025-07-24 22:59:45 - utils.audio_utils - INFO - Audio preprocessed: 20480 samples
2025-07-24 22:59:45 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:46 - services.transcription_service - INFO - Transcription completed: 'Hello, warriors.' (16 characters)
2025-07-24 22:59:46 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 22:59:46 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:59:46 - services.emotion_service - INFO - Enhanced rule-based emotion detected: neutral (confidence: 0.400)
2025-07-24 22:59:53 - routes.api - INFO - Audio data decoded successfully: 51359 bytes, format: webm
2025-07-24 22:59:53 - utils.audio_utils - INFO - Loading audio: 51359 bytes, format: webm
2025-07-24 22:59:53 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 22:59:53 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpn_varoig.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpn_varoig.wav
2025-07-24 22:59:53 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 22:59:53 - utils.audio_utils - INFO - Audio loaded successfully: 50880 samples, 16000Hz
2025-07-24 22:59:53 - utils.audio_utils - INFO - Audio preprocessed: 20992 samples
2025-07-24 22:59:53 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 22:59:54 - services.transcription_service - INFO - Transcription completed: 'Hello, glorious' (15 characters)
2025-07-24 22:59:54 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 22:59:54 - services.transcription_service - INFO - Model used: whisper
2025-07-24 22:59:54 - services.emotion_service - INFO - Enhanced rule-based emotion detected: neutral (confidence: 0.400)
2025-07-24 23:00:01 - routes.api - INFO - Audio data decoded successfully: 24311 bytes, format: webm
2025-07-24 23:00:01 - utils.audio_utils - INFO - Loading audio: 24311 bytes, format: webm
2025-07-24 23:00:01 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 23:00:01 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp7y_f_swh.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp7y_f_swh.wav
2025-07-24 23:00:01 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 23:00:01 - utils.audio_utils - INFO - Audio loaded successfully: 24000 samples, 16000Hz
2025-07-24 23:00:01 - utils.audio_utils - INFO - Audio preprocessed: 19968 samples
2025-07-24 23:00:01 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 23:00:02 - services.transcription_service - INFO - Transcription completed: 'I'm excited.' (12 characters)
2025-07-24 23:00:02 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 23:00:02 - services.transcription_service - INFO - Model used: whisper
2025-07-24 23:00:02 - services.emotion_service - INFO - Enhanced rule-based emotion detected: happy (confidence: 0.300)
2025-07-24 23:01:05 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 23:01:05 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 23:01:05 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 23:01:05 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 23:01:05 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 23:01:07 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 23:01:07 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 23:01:07 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 23:01:07 - services.emotion_service - ERROR - Failed to initialize emotion models: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-07-24 23:01:07 - services.emotion_service - INFO - Falling back to rule-based emotion detection
2025-07-24 23:01:07 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 23:02:28 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 23:02:28 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 23:02:28 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 23:02:28 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 23:02:28 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 23:02:31 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 23:02:31 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 23:02:31 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-24 23:02:31 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 23:02:31 - services.emotion_service - INFO - Initializing emotion pipeline with model: m3hrdadfi/emotion-english-distilroberta-base
2025-07-24 23:02:31 - services.emotion_service - ERROR - Failed to initialize emotion models: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\requests\models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1346, in hf_hub_download
    raise head_call_error
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1232, in hf_hub_download
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1608, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 293, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-688301d7-00e434ff31e78aab4ec01e5e;67292dae-e6a9-4e04-9b0a-92f9c3089c96)

Repository Not Found for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\emotion_service.py", line 54, in _initialize_models
    self.text_emotion_pipeline = pipeline(
                                 ^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\pipelines\__init__.py", line 747, in pipeline
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 451, in cached_file
    raise EnvironmentError(
OSError: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`

2025-07-24 23:02:31 - services.emotion_service - INFO - Falling back to rule-based emotion detection
2025-07-24 23:02:31 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 23:02:39 - routes.api - INFO - Audio data decoded successfully: 30107 bytes, format: webm
2025-07-24 23:02:39 - utils.audio_utils - INFO - Loading audio: 30107 bytes, format: webm
2025-07-24 23:02:39 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 23:02:39 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpqby662ex.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpqby662ex.wav
2025-07-24 23:02:40 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 23:02:42 - utils.audio_utils - INFO - Audio loaded successfully: 29760 samples, 16000Hz
2025-07-24 23:02:42 - utils.audio_utils - INFO - Audio preprocessed: 22528 samples
2025-07-24 23:02:42 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 23:02:43 - services.transcription_service - INFO - Transcription completed: 'Here's a quick test.' (20 characters)
2025-07-24 23:02:43 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-24 23:02:43 - services.transcription_service - INFO - Model used: whisper
2025-07-24 23:02:43 - services.emotion_service - INFO - Using rule-based emotion detection (fallback)
2025-07-24 23:02:43 - services.emotion_service - INFO - Enhanced rule-based emotion detected: neutral (confidence: 0.400)
2025-07-24 23:03:55 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 23:03:55 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 23:03:56 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 23:03:56 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 23:03:56 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 23:03:58 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 23:03:58 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 23:03:58 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-24 23:03:58 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 23:03:58 - services.emotion_service - INFO - Initializing emotion pipeline with model: m3hrdadfi/emotion-english-distilroberta-base
2025-07-24 23:03:58 - services.emotion_service - ERROR - Failed to initialize emotion models: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\requests\models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1346, in hf_hub_download
    raise head_call_error
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1232, in hf_hub_download
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1608, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 293, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-6883022e-58684c9a361bd1257d294f50;03b76f8a-b4b7-4b55-bd1d-49f0165f3613)

Repository Not Found for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\emotion_service.py", line 54, in _initialize_models
    self.text_emotion_pipeline = pipeline(
                                 ^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\pipelines\__init__.py", line 747, in pipeline
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 451, in cached_file
    raise EnvironmentError(
OSError: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`

2025-07-24 23:03:58 - services.emotion_service - INFO - Falling back to rule-based emotion detection
2025-07-24 23:03:58 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 23:04:30 - routes.api - INFO - Audio data decoded successfully: 25277 bytes, format: webm
2025-07-24 23:04:30 - utils.audio_utils - INFO - Loading audio: 25277 bytes, format: webm
2025-07-24 23:04:30 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 23:04:30 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpaz8vhgnu.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpaz8vhgnu.wav
2025-07-24 23:04:30 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 23:04:32 - utils.audio_utils - INFO - Audio loaded successfully: 24960 samples, 16000Hz
2025-07-24 23:04:32 - utils.audio_utils - INFO - Audio preprocessed: 19456 samples
2025-07-24 23:04:32 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 23:04:33 - services.transcription_service - INFO - Transcription completed: 'I'm scared.' (11 characters)
2025-07-24 23:04:33 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 23:04:33 - services.transcription_service - INFO - Model used: whisper
2025-07-24 23:04:33 - services.emotion_service - INFO - Using rule-based emotion detection (fallback)
2025-07-24 23:04:33 - services.emotion_service - INFO - Enhanced rule-based emotion detected: fear (confidence: 0.300)
2025-07-24 23:05:33 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 23:05:33 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 23:05:33 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 23:05:33 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 23:05:33 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 23:05:35 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 23:05:35 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 23:05:35 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-24 23:05:35 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 23:05:35 - services.emotion_service - INFO - Initializing emotion pipeline with model: m3hrdadfi/emotion-english-distilroberta-base
2025-07-24 23:05:35 - services.emotion_service - ERROR - Failed to initialize emotion models: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\requests\models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1346, in hf_hub_download
    raise head_call_error
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1232, in hf_hub_download
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1608, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 293, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-6883028f-00af8e230ce67a867706d317;a829d1d2-7a39-4071-bf93-5facc9471971)

Repository Not Found for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\emotion_service.py", line 54, in _initialize_models
    self.text_emotion_pipeline = pipeline(
                                 ^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\pipelines\__init__.py", line 747, in pipeline
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 451, in cached_file
    raise EnvironmentError(
OSError: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`

2025-07-24 23:05:35 - services.emotion_service - INFO - Falling back to rule-based emotion detection
2025-07-24 23:05:35 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 23:05:54 - routes.api - INFO - Audio data decoded successfully: 29141 bytes, format: webm
2025-07-24 23:05:54 - utils.audio_utils - INFO - Loading audio: 29141 bytes, format: webm
2025-07-24 23:05:54 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 23:05:54 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpp1lh8z89.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpp1lh8z89.wav
2025-07-24 23:05:54 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 23:05:56 - utils.audio_utils - INFO - Audio loaded successfully: 28800 samples, 16000Hz
2025-07-24 23:05:57 - utils.audio_utils - INFO - Audio preprocessed: 26112 samples
2025-07-24 23:05:57 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 23:05:57 - services.transcription_service - INFO - Transcription completed: 'I'm scared.' (11 characters)
2025-07-24 23:05:57 - services.transcription_service - INFO - Confidence: 0.7
2025-07-24 23:05:57 - services.transcription_service - INFO - Model used: whisper
2025-07-24 23:05:57 - services.emotion_service - INFO - Using rule-based emotion detection (fallback)
2025-07-24 23:05:57 - services.emotion_service - INFO - Enhanced rule-based emotion detected: fear (confidence: 0.300)
2025-07-24 23:06:40 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 23:06:40 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 23:06:40 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 23:06:40 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 23:06:40 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 23:06:43 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 23:06:43 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 23:06:43 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-24 23:06:43 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 23:06:43 - services.emotion_service - INFO - Initializing emotion pipeline with model: m3hrdadfi/emotion-english-distilroberta-base
2025-07-24 23:06:43 - services.emotion_service - ERROR - Failed to initialize emotion models: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\requests\models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1346, in hf_hub_download
    raise head_call_error
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1232, in hf_hub_download
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\file_download.py", line 1608, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\huggingface_hub\utils\_errors.py", line 293, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-688302d3-4a6824751231b0f8658726c6;41db9adf-c580-4bca-9b3c-566e3a9f6f32)

Repository Not Found for url: https://huggingface.co/m3hrdadfi/emotion-english-distilroberta-base/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "X:\Projects\Personal Projects\Tone Bridge\backend\services\emotion_service.py", line 54, in _initialize_models
    self.text_emotion_pipeline = pipeline(
                                 ^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\pipelines\__init__.py", line 747, in pipeline
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\transformers\utils\hub.py", line 451, in cached_file
    raise EnvironmentError(
OSError: m3hrdadfi/emotion-english-distilroberta-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`

2025-07-24 23:06:43 - services.emotion_service - INFO - Falling back to rule-based emotion detection
2025-07-24 23:06:43 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 23:07:11 - routes.api - INFO - Audio data decoded successfully: 34937 bytes, format: webm
2025-07-24 23:07:11 - utils.audio_utils - INFO - Loading audio: 34937 bytes, format: webm
2025-07-24 23:07:11 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 23:07:11 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpzgne9454.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpzgne9454.wav
2025-07-24 23:07:11 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 23:07:14 - utils.audio_utils - INFO - Audio loaded successfully: 34560 samples, 16000Hz
2025-07-24 23:07:14 - utils.audio_utils - INFO - Audio preprocessed: 28160 samples
2025-07-24 23:07:14 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 23:07:15 - services.transcription_service - INFO - Transcription completed: 'Man, this sucks.' (16 characters)
2025-07-24 23:07:15 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-07-24 23:07:15 - services.transcription_service - INFO - Model used: whisper
2025-07-24 23:07:15 - services.emotion_service - INFO - Using rule-based emotion detection (fallback)
2025-07-24 23:07:15 - services.emotion_service - INFO - Enhanced rule-based emotion detected: neutral (confidence: 0.400)
2025-07-24 23:08:41 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-24 23:08:41 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-24 23:08:41 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-24 23:08:41 - services.transcription_service - INFO - Using CPU for transcription
2025-07-24 23:08:41 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-24 23:08:44 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-24 23:08:44 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-24 23:08:44 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-24 23:08:44 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-24 23:08:44 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-24 23:10:21 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-24 23:10:21 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-24 23:10:21 - app - INFO - ToneBridge Backend initialized successfully
2025-07-24 23:11:14 - routes.api - INFO - Audio data decoded successfully: 34937 bytes, format: webm
2025-07-24 23:11:14 - utils.audio_utils - INFO - Loading audio: 34937 bytes, format: webm
2025-07-24 23:11:14 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 23:11:14 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpym25eua0.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpym25eua0.wav
2025-07-24 23:11:14 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 23:11:17 - utils.audio_utils - INFO - Audio loaded successfully: 34560 samples, 16000Hz
2025-07-24 23:11:17 - utils.audio_utils - INFO - Audio preprocessed: 20480 samples
2025-07-24 23:11:17 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 23:11:18 - services.transcription_service - INFO - Transcription completed: 'Wow' (3 characters)
2025-07-24 23:11:18 - services.transcription_service - INFO - Confidence: 0.5
2025-07-24 23:11:18 - services.transcription_service - INFO - Model used: whisper
2025-07-24 23:11:18 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-24 23:11:19 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.778)
2025-07-24 23:11:27 - routes.api - INFO - Audio data decoded successfully: 47495 bytes, format: webm
2025-07-24 23:11:27 - utils.audio_utils - INFO - Loading audio: 47495 bytes, format: webm
2025-07-24 23:11:27 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-24 23:11:27 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpt8yjvg8z.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpt8yjvg8z.wav
2025-07-24 23:11:27 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-24 23:11:27 - utils.audio_utils - INFO - Audio loaded successfully: 47040 samples, 16000Hz
2025-07-24 23:11:27 - utils.audio_utils - INFO - Audio preprocessed: 33792 samples
2025-07-24 23:11:27 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-24 23:11:28 - services.transcription_service - INFO - Transcription completed: 'Wow this really sucks' (21 characters)
2025-07-24 23:11:28 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-07-24 23:11:28 - services.transcription_service - INFO - Model used: whisper
2025-07-24 23:11:28 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-24 23:11:28 - services.emotion_service - INFO - Text emotion detected: frustrated (confidence: 0.577)
2025-07-25 18:23:31 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-25 18:23:31 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-25 18:23:31 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-25 18:23:31 - services.transcription_service - INFO - Using CPU for transcription
2025-07-25 18:23:31 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-25 18:23:35 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-25 18:23:35 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-25 18:23:35 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-25 18:23:35 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-25 18:23:35 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-25 18:23:37 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-25 18:23:37 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-25 18:23:37 - app - INFO - ToneBridge Backend initialized successfully
2025-07-25 18:26:59 - routes.api - INFO - Audio data decoded successfully: 36869 bytes, format: webm
2025-07-25 18:26:59 - utils.audio_utils - INFO - Loading audio: 36869 bytes, format: webm
2025-07-25 18:26:59 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:26:59 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp69ktj6u7.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp69ktj6u7.wav
2025-07-25 18:27:00 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:27:05 - utils.audio_utils - INFO - Audio loaded successfully: 36480 samples, 16000Hz
2025-07-25 18:27:07 - utils.audio_utils - INFO - Audio preprocessed: 34304 samples
2025-07-25 18:27:07 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:27:08 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:27:08 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:27:08 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:27:08 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:27:10 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:30:04 - routes.api - INFO - Audio data decoded successfully: 36869 bytes, format: webm
2025-07-25 18:30:04 - utils.audio_utils - INFO - Loading audio: 36869 bytes, format: webm
2025-07-25 18:30:04 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:30:04 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpg6gcfow1.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpg6gcfow1.wav
2025-07-25 18:30:04 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:30:04 - utils.audio_utils - INFO - Audio loaded successfully: 36480 samples, 16000Hz
2025-07-25 18:30:04 - utils.audio_utils - INFO - Audio preprocessed: 4608 samples
2025-07-25 18:30:04 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:30:05 - services.transcription_service - INFO - Transcription completed: 'Thank you.' (10 characters)
2025-07-25 18:30:05 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 18:30:05 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:30:05 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:30:05 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.990)
2025-07-25 18:31:57 - routes.api - INFO - Audio data decoded successfully: 25277 bytes, format: webm
2025-07-25 18:31:57 - utils.audio_utils - INFO - Loading audio: 25277 bytes, format: webm
2025-07-25 18:31:57 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:31:57 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpwdn65b75.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpwdn65b75.wav
2025-07-25 18:31:57 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:31:57 - utils.audio_utils - INFO - Audio loaded successfully: 24960 samples, 16000Hz
2025-07-25 18:31:57 - utils.audio_utils - INFO - Audio preprocessed: 3072 samples
2025-07-25 18:31:57 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:31:58 - services.transcription_service - INFO - Transcription completed: 'Thank you.' (10 characters)
2025-07-25 18:31:58 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 18:31:58 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:31:58 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:31:58 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.990)
2025-07-25 18:41:30 - routes.api - INFO - Audio data decoded successfully: 24311 bytes, format: webm
2025-07-25 18:41:30 - utils.audio_utils - INFO - Loading audio: 24311 bytes, format: webm
2025-07-25 18:41:30 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:41:30 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp3nl4l3gj.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp3nl4l3gj.wav
2025-07-25 18:41:31 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:41:31 - utils.audio_utils - INFO - Audio loaded successfully: 24000 samples, 16000Hz
2025-07-25 18:41:31 - utils.audio_utils - INFO - Audio preprocessed: 7680 samples
2025-07-25 18:41:31 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:41:32 - services.transcription_service - INFO - Transcription completed: 'you.' (4 characters)
2025-07-25 18:41:32 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:41:32 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:41:32 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:41:32 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.959)
2025-07-25 18:43:46 - routes.api - INFO - Audio data decoded successfully: 13685 bytes, format: webm
2025-07-25 18:43:46 - utils.audio_utils - INFO - Loading audio: 13685 bytes, format: webm
2025-07-25 18:43:46 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:43:46 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp8rx6wv_i.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp8rx6wv_i.wav
2025-07-25 18:43:46 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:43:46 - utils.audio_utils - INFO - Audio loaded successfully: 13440 samples, 16000Hz
2025-07-25 18:43:46 - utils.audio_utils - INFO - Audio preprocessed: 8704 samples
2025-07-25 18:43:46 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:43:47 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:43:47 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:43:47 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:43:47 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:43:47 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:43:49 - routes.api - INFO - Audio data decoded successfully: 13685 bytes, format: webm
2025-07-25 18:43:49 - utils.audio_utils - INFO - Loading audio: 13685 bytes, format: webm
2025-07-25 18:43:49 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:43:49 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpzczm27q7.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpzczm27q7.wav
2025-07-25 18:43:49 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:43:49 - utils.audio_utils - INFO - Audio loaded successfully: 13440 samples, 16000Hz
2025-07-25 18:43:49 - utils.audio_utils - INFO - Audio preprocessed: 5120 samples
2025-07-25 18:43:49 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:43:50 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:43:50 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:43:50 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:43:50 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:43:50 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:43:53 - routes.api - INFO - Audio data decoded successfully: 12719 bytes, format: webm
2025-07-25 18:43:53 - utils.audio_utils - INFO - Loading audio: 12719 bytes, format: webm
2025-07-25 18:43:53 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:43:53 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp6gkb2sn0.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp6gkb2sn0.wav
2025-07-25 18:43:53 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:43:53 - utils.audio_utils - INFO - Audio loaded successfully: 12480 samples, 16000Hz
2025-07-25 18:43:53 - utils.audio_utils - INFO - Audio preprocessed: 5120 samples
2025-07-25 18:43:53 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:43:54 - services.transcription_service - INFO - Transcription completed: 'BAM!' (4 characters)
2025-07-25 18:43:54 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:43:54 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:43:54 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:43:54 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.360)
2025-07-25 18:44:00 - routes.api - INFO - Audio data decoded successfully: 7889 bytes, format: webm
2025-07-25 18:44:00 - utils.audio_utils - INFO - Loading audio: 7889 bytes, format: webm
2025-07-25 18:44:00 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:44:00 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpl0omsvtc.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpl0omsvtc.wav
2025-07-25 18:44:00 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:44:00 - utils.audio_utils - INFO - Audio loaded successfully: 7680 samples, 16000Hz
2025-07-25 18:44:00 - utils.audio_utils - INFO - Audio preprocessed: 7168 samples
2025-07-25 18:44:00 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:44:01 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:44:01 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:44:01 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:44:01 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:44:01 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:44:17 - routes.api - INFO - Audio data decoded successfully: 7889 bytes, format: webm
2025-07-25 18:44:17 - utils.audio_utils - INFO - Loading audio: 7889 bytes, format: webm
2025-07-25 18:44:17 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:44:17 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp1_8val37.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp1_8val37.wav
2025-07-25 18:44:18 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:44:18 - utils.audio_utils - INFO - Audio loaded successfully: 7680 samples, 16000Hz
2025-07-25 18:44:18 - utils.audio_utils - INFO - Audio preprocessed: 7168 samples
2025-07-25 18:44:18 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:44:18 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:44:18 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:44:18 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:44:18 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:44:18 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:45:37 - routes.api - INFO - Audio data decoded successfully: 48461 bytes, format: webm
2025-07-25 18:45:37 - utils.audio_utils - INFO - Loading audio: 48461 bytes, format: webm
2025-07-25 18:45:37 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:45:37 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp1cmxl01c.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp1cmxl01c.wav
2025-07-25 18:45:37 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:45:37 - utils.audio_utils - INFO - Audio loaded successfully: 48000 samples, 16000Hz
2025-07-25 18:45:37 - utils.audio_utils - INFO - Audio preprocessed: 36352 samples
2025-07-25 18:45:37 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:45:38 - services.transcription_service - INFO - Transcription completed: 'BAM!' (4 characters)
2025-07-25 18:45:38 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:45:38 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:45:38 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:45:39 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.360)
2025-07-25 18:45:47 - routes.api - INFO - Audio data decoded successfully: 54257 bytes, format: webm
2025-07-25 18:45:47 - utils.audio_utils - INFO - Loading audio: 54257 bytes, format: webm
2025-07-25 18:45:47 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:45:47 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpwn12h6r_.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpwn12h6r_.wav
2025-07-25 18:45:47 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:45:47 - utils.audio_utils - INFO - Audio loaded successfully: 53760 samples, 16000Hz
2025-07-25 18:45:47 - utils.audio_utils - INFO - Audio preprocessed: 36352 samples
2025-07-25 18:45:47 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:45:48 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:45:48 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:45:48 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:45:48 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:45:48 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:45:53 - routes.api - INFO - Audio data decoded successfully: 31073 bytes, format: webm
2025-07-25 18:45:53 - utils.audio_utils - INFO - Loading audio: 31073 bytes, format: webm
2025-07-25 18:45:53 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:45:53 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpxmgo1kjn.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpxmgo1kjn.wav
2025-07-25 18:45:53 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:45:53 - utils.audio_utils - INFO - Audio loaded successfully: 30720 samples, 16000Hz
2025-07-25 18:45:53 - utils.audio_utils - INFO - Audio preprocessed: 5120 samples
2025-07-25 18:45:53 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:45:54 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:45:54 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:45:54 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:45:54 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:45:54 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:47:33 - routes.api - INFO - Audio data decoded successfully: 29141 bytes, format: webm
2025-07-25 18:47:33 - utils.audio_utils - INFO - Loading audio: 29141 bytes, format: webm
2025-07-25 18:47:33 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:47:33 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpims_k0k1.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpims_k0k1.wav
2025-07-25 18:47:33 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:47:33 - utils.audio_utils - INFO - Audio loaded successfully: 28800 samples, 16000Hz
2025-07-25 18:47:33 - utils.audio_utils - INFO - Audio preprocessed: 2048 samples
2025-07-25 18:47:33 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:47:34 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:47:34 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:47:34 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:47:34 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:47:34 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:48:30 - routes.api - INFO - Audio data decoded successfully: 12719 bytes, format: webm
2025-07-25 18:48:30 - utils.audio_utils - INFO - Loading audio: 12719 bytes, format: webm
2025-07-25 18:48:30 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:48:30 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp4xs1vsra.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp4xs1vsra.wav
2025-07-25 18:48:30 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:48:30 - utils.audio_utils - INFO - Audio loaded successfully: 12480 samples, 16000Hz
2025-07-25 18:48:30 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-07-25 18:48:30 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:48:31 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:48:31 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:48:31 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:48:31 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:48:31 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:50:29 - routes.api - INFO - Audio data decoded successfully: 15617 bytes, format: webm
2025-07-25 18:50:29 - utils.audio_utils - INFO - Loading audio: 15617 bytes, format: webm
2025-07-25 18:50:29 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:50:29 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp3prpc3s5.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp3prpc3s5.wav
2025-07-25 18:50:29 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:50:29 - utils.audio_utils - INFO - Audio loaded successfully: 15360 samples, 16000Hz
2025-07-25 18:50:29 - utils.audio_utils - INFO - Audio preprocessed: 7168 samples
2025-07-25 18:50:29 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:50:30 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:50:30 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:50:30 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:50:30 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:50:30 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:50:35 - routes.api - INFO - Audio data decoded successfully: 23345 bytes, format: webm
2025-07-25 18:50:35 - utils.audio_utils - INFO - Loading audio: 23345 bytes, format: webm
2025-07-25 18:50:35 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:50:35 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpw5n48n_t.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpw5n48n_t.wav
2025-07-25 18:50:35 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:50:35 - utils.audio_utils - INFO - Audio loaded successfully: 23040 samples, 16000Hz
2025-07-25 18:50:35 - utils.audio_utils - INFO - Audio preprocessed: 8192 samples
2025-07-25 18:50:35 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:50:36 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-25 18:50:36 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:50:36 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:50:36 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:50:36 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 18:56:48 - routes.api - INFO - Audio data decoded successfully: 7889 bytes, format: webm
2025-07-25 18:56:48 - utils.audio_utils - INFO - Loading audio: 7889 bytes, format: webm
2025-07-25 18:56:48 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:56:48 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp7186rd5n.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp7186rd5n.wav
2025-07-25 18:56:48 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:56:48 - utils.audio_utils - INFO - Audio loaded successfully: 7680 samples, 16000Hz
2025-07-25 18:56:48 - utils.audio_utils - INFO - Audio preprocessed: 5120 samples
2025-07-25 18:56:48 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:56:49 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-25 18:56:49 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 18:56:49 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:56:49 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:56:49 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-25 18:58:17 - routes.api - INFO - Audio data decoded successfully: 9821 bytes, format: webm
2025-07-25 18:58:17 - utils.audio_utils - INFO - Loading audio: 9821 bytes, format: webm
2025-07-25 18:58:17 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:58:17 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpxfx5krt7.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpxfx5krt7.wav
2025-07-25 18:58:17 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:58:17 - utils.audio_utils - INFO - Audio loaded successfully: 9600 samples, 16000Hz
2025-07-25 18:58:17 - utils.audio_utils - INFO - Audio preprocessed: 4608 samples
2025-07-25 18:58:17 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:58:18 - services.transcription_service - INFO - Transcription completed: 'BAM!' (4 characters)
2025-07-25 18:58:18 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:58:18 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:58:18 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:58:19 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.360)
2025-07-25 18:58:46 - routes.api - INFO - Audio data decoded successfully: 8855 bytes, format: webm
2025-07-25 18:58:46 - utils.audio_utils - INFO - Loading audio: 8855 bytes, format: webm
2025-07-25 18:58:46 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:58:46 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpylcllmog.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpylcllmog.wav
2025-07-25 18:58:46 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:58:46 - utils.audio_utils - INFO - Audio loaded successfully: 8640 samples, 16000Hz
2025-07-25 18:58:46 - utils.audio_utils - INFO - Audio preprocessed: 5120 samples
2025-07-25 18:58:46 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:58:47 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-25 18:58:47 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 18:58:47 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:58:47 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:58:47 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-25 18:59:46 - routes.api - INFO - Audio data decoded successfully: 5957 bytes, format: webm
2025-07-25 18:59:46 - utils.audio_utils - INFO - Loading audio: 5957 bytes, format: webm
2025-07-25 18:59:46 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 18:59:46 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpfb5lunws.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpfb5lunws.wav
2025-07-25 18:59:46 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 18:59:46 - utils.audio_utils - INFO - Audio loaded successfully: 5760 samples, 16000Hz
2025-07-25 18:59:46 - utils.audio_utils - INFO - Audio preprocessed: 5120 samples
2025-07-25 18:59:46 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 18:59:47 - services.transcription_service - INFO - Transcription completed: 'BAM!' (4 characters)
2025-07-25 18:59:47 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 18:59:47 - services.transcription_service - INFO - Model used: whisper
2025-07-25 18:59:47 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 18:59:47 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.360)
2025-07-25 19:04:00 - routes.api - INFO - Audio data decoded successfully: 19481 bytes, format: webm
2025-07-25 19:04:00 - utils.audio_utils - INFO - Loading audio: 19481 bytes, format: webm
2025-07-25 19:04:00 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 19:04:00 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmptplupxp4.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmptplupxp4.wav
2025-07-25 19:04:00 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 19:04:00 - utils.audio_utils - INFO - Audio loaded successfully: 19200 samples, 16000Hz
2025-07-25 19:04:00 - utils.audio_utils - INFO - Audio preprocessed: 4608 samples
2025-07-25 19:04:00 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 19:04:01 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-25 19:04:01 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 19:04:01 - services.transcription_service - INFO - Model used: whisper
2025-07-25 19:04:01 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 19:04:01 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-25 19:25:26 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-25 19:25:26 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-25 19:25:26 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-25 19:25:26 - services.transcription_service - INFO - Using CPU for transcription
2025-07-25 19:25:26 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-25 19:25:30 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-25 19:25:30 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-25 19:25:30 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-25 19:25:30 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-25 19:25:30 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-25 19:25:31 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-25 19:25:31 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-25 19:25:31 - app - INFO - ToneBridge Backend initialized successfully
2025-07-25 19:32:41 - routes.api - INFO - Audio data decoded successfully: 42665 bytes, format: webm
2025-07-25 19:32:41 - utils.audio_utils - INFO - Loading audio: 42665 bytes, format: webm
2025-07-25 19:32:41 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 19:32:41 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmptv_gaw4x.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmptv_gaw4x.wav
2025-07-25 19:32:42 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 19:32:44 - utils.audio_utils - INFO - Audio loaded successfully: 42240 samples, 16000Hz
2025-07-25 19:32:45 - utils.audio_utils - INFO - Audio preprocessed: 13824 samples
2025-07-25 19:32:45 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 19:32:46 - services.transcription_service - INFO - Transcription completed: 'Hello, testing.' (15 characters)
2025-07-25 19:32:46 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 19:32:46 - services.transcription_service - INFO - Model used: whisper
2025-07-25 19:32:46 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 19:32:47 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-25 19:40:35 - routes.api - INFO - Audio data decoded successfully: 77441 bytes, format: webm
2025-07-25 19:40:35 - utils.audio_utils - INFO - Loading audio: 77441 bytes, format: webm
2025-07-25 19:40:35 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 19:40:35 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpj5bc7src.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpj5bc7src.wav
2025-07-25 19:40:35 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 19:40:35 - utils.audio_utils - INFO - Audio loaded successfully: 76800 samples, 16000Hz
2025-07-25 19:40:35 - utils.audio_utils - INFO - Audio preprocessed: 34304 samples
2025-07-25 19:40:35 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 19:40:36 - services.transcription_service - INFO - Transcription completed: 'That's through through through testing.' (39 characters)
2025-07-25 19:40:36 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-07-25 19:40:36 - services.transcription_service - INFO - Model used: whisper
2025-07-25 19:40:36 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 19:40:36 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.954)
2025-07-25 20:12:32 - routes.api - INFO - Audio data decoded successfully: 69713 bytes, format: webm
2025-07-25 20:12:32 - utils.audio_utils - INFO - Loading audio: 69713 bytes, format: webm
2025-07-25 20:12:32 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 20:12:32 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpb755a9ek.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpb755a9ek.wav
2025-07-25 20:12:32 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 20:12:32 - utils.audio_utils - INFO - Audio loaded successfully: 69120 samples, 16000Hz
2025-07-25 20:12:32 - utils.audio_utils - INFO - Audio preprocessed: 37888 samples
2025-07-25 20:12:32 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 20:12:33 - services.transcription_service - INFO - Transcription completed: 'I wonder why this guy is beautiful.' (35 characters)
2025-07-25 20:12:33 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-07-25 20:12:33 - services.transcription_service - INFO - Model used: whisper
2025-07-25 20:12:33 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 20:12:33 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.873)
2025-07-25 20:12:46 - routes.api - INFO - Audio data decoded successfully: 73577 bytes, format: webm
2025-07-25 20:12:46 - utils.audio_utils - INFO - Loading audio: 73577 bytes, format: webm
2025-07-25 20:12:46 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 20:12:46 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpuzj4crct.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpuzj4crct.wav
2025-07-25 20:12:46 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 20:12:46 - utils.audio_utils - INFO - Audio loaded successfully: 72960 samples, 16000Hz
2025-07-25 20:12:46 - utils.audio_utils - INFO - Audio preprocessed: 47616 samples
2025-07-25 20:12:46 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 20:12:47 - services.transcription_service - INFO - Transcription completed: 'I wonder why the sky is blue.' (29 characters)
2025-07-25 20:12:47 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-25 20:12:47 - services.transcription_service - INFO - Model used: whisper
2025-07-25 20:12:47 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 20:12:47 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.761)
2025-07-25 20:58:01 - routes.api - INFO - Audio data decoded successfully: 22379 bytes, format: webm
2025-07-25 20:58:01 - utils.audio_utils - INFO - Loading audio: 22379 bytes, format: webm
2025-07-25 20:58:01 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 20:58:01 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp0nt9fc1_.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp0nt9fc1_.wav
2025-07-25 20:58:02 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 20:58:02 - utils.audio_utils - INFO - Audio loaded successfully: 22080 samples, 16000Hz
2025-07-25 20:58:02 - utils.audio_utils - INFO - Audio preprocessed: 22080 samples
2025-07-25 20:58:02 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 20:58:03 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-25 20:58:03 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 20:58:03 - services.transcription_service - INFO - Model used: whisper
2025-07-25 20:58:03 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 20:58:03 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-25 21:53:24 - routes.api - INFO - Audio data decoded successfully: 17549 bytes, format: webm
2025-07-25 21:53:24 - utils.audio_utils - INFO - Loading audio: 17549 bytes, format: webm
2025-07-25 21:53:24 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 21:53:24 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp9n0_5gbr.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp9n0_5gbr.wav
2025-07-25 21:53:24 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 21:53:24 - utils.audio_utils - INFO - Audio loaded successfully: 17280 samples, 16000Hz
2025-07-25 21:53:24 - utils.audio_utils - INFO - Audio preprocessed: 17280 samples
2025-07-25 21:53:24 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 21:53:25 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-25 21:53:25 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 21:53:25 - services.transcription_service - INFO - Model used: whisper
2025-07-25 21:53:25 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 21:53:25 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-25 21:59:08 - routes.api - INFO - Audio data decoded successfully: 23345 bytes, format: webm
2025-07-25 21:59:08 - utils.audio_utils - INFO - Loading audio: 23345 bytes, format: webm
2025-07-25 21:59:08 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 21:59:08 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpgbkzs9eu.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpgbkzs9eu.wav
2025-07-25 21:59:08 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 21:59:08 - utils.audio_utils - INFO - Audio loaded successfully: 23040 samples, 16000Hz
2025-07-25 21:59:08 - utils.audio_utils - INFO - Audio preprocessed: 23040 samples
2025-07-25 21:59:08 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 21:59:09 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-25 21:59:09 - services.transcription_service - INFO - Confidence: 0.5
2025-07-25 21:59:09 - services.transcription_service - INFO - Model used: whisper
2025-07-25 21:59:09 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 21:59:09 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-25 21:59:18 - routes.api - INFO - Audio data decoded successfully: 49427 bytes, format: webm
2025-07-25 21:59:18 - utils.audio_utils - INFO - Loading audio: 49427 bytes, format: webm
2025-07-25 21:59:18 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 21:59:18 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmplbc2dte3.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmplbc2dte3.wav
2025-07-25 21:59:18 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 21:59:18 - utils.audio_utils - INFO - Audio loaded successfully: 48960 samples, 16000Hz
2025-07-25 21:59:18 - utils.audio_utils - INFO - Audio preprocessed: 48960 samples
2025-07-25 21:59:18 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 21:59:19 - services.transcription_service - INFO - Transcription completed: 'I'm going to use the same method as the other one.' (50 characters)
2025-07-25 21:59:19 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-25 21:59:19 - services.transcription_service - INFO - Model used: whisper
2025-07-25 21:59:19 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 21:59:19 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.598)
2025-07-25 22:19:05 - routes.api - INFO - Audio data decoded successfully: 54257 bytes, format: webm
2025-07-25 22:19:05 - utils.audio_utils - INFO - Loading audio: 54257 bytes, format: webm
2025-07-25 22:19:05 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 22:19:05 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmppp9sarun.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmppp9sarun.wav
2025-07-25 22:19:06 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 22:19:06 - utils.audio_utils - INFO - Audio loaded successfully: 53760 samples, 16000Hz
2025-07-25 22:19:06 - utils.audio_utils - INFO - Audio preprocessed: 36864 samples
2025-07-25 22:19:06 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 22:19:07 - services.transcription_service - INFO - Transcription completed: 'Testing, testing, one, two, three, testing.' (43 characters)
2025-07-25 22:19:07 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-07-25 22:19:07 - services.transcription_service - INFO - Model used: whisper
2025-07-25 22:19:07 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 22:19:07 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-25 22:26:10 - routes.api - INFO - Audio data decoded successfully: 29141 bytes, format: webm
2025-07-25 22:26:10 - utils.audio_utils - INFO - Loading audio: 29141 bytes, format: webm
2025-07-25 22:26:10 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 22:26:10 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpo5bpfi_d.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpo5bpfi_d.wav
2025-07-25 22:26:10 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 22:26:10 - utils.audio_utils - INFO - Audio loaded successfully: 28800 samples, 16000Hz
2025-07-25 22:26:10 - utils.audio_utils - INFO - Audio preprocessed: 17408 samples
2025-07-25 22:26:10 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 22:26:12 - services.transcription_service - INFO - Transcription completed: 'testing testing.' (16 characters)
2025-07-25 22:26:12 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 22:26:12 - services.transcription_service - INFO - Model used: whisper
2025-07-25 22:26:12 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 22:26:12 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-25 22:27:08 - routes.api - INFO - Audio data decoded successfully: 31073 bytes, format: webm
2025-07-25 22:27:08 - utils.audio_utils - INFO - Loading audio: 31073 bytes, format: webm
2025-07-25 22:27:08 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-25 22:27:08 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpmiluxzxw.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpmiluxzxw.wav
2025-07-25 22:27:08 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-25 22:27:08 - utils.audio_utils - INFO - Audio loaded successfully: 30720 samples, 16000Hz
2025-07-25 22:27:08 - utils.audio_utils - INFO - Audio preprocessed: 15360 samples
2025-07-25 22:27:08 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-25 22:27:09 - services.transcription_service - INFO - Transcription completed: 'testing testing' (15 characters)
2025-07-25 22:27:09 - services.transcription_service - INFO - Confidence: 0.7
2025-07-25 22:27:09 - services.transcription_service - INFO - Model used: whisper
2025-07-25 22:27:09 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-25 22:27:09 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 00:10:51 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-26 00:10:51 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-26 00:10:51 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-26 00:10:51 - services.transcription_service - INFO - Using CPU for transcription
2025-07-26 00:10:51 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-26 00:10:55 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-26 00:10:55 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-26 00:10:55 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-26 00:10:55 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-26 00:10:55 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-26 00:10:57 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-26 00:10:57 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-26 00:10:57 - app - INFO - ToneBridge Backend initialized successfully
2025-07-26 06:50:11 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-26 06:50:11 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-26 06:50:11 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-26 06:50:11 - services.transcription_service - INFO - Using CPU for transcription
2025-07-26 06:50:11 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-26 06:50:15 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-26 06:50:15 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-26 06:50:15 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-26 06:50:15 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-26 06:50:15 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-26 06:50:17 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-26 06:50:17 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-26 06:50:17 - app - INFO - ToneBridge Backend initialized successfully
2025-07-26 06:59:36 - routes.api - INFO - Audio data decoded successfully: 78407 bytes, format: webm
2025-07-26 06:59:36 - utils.audio_utils - INFO - Loading audio: 78407 bytes, format: webm
2025-07-26 06:59:36 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 06:59:36 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpywxd6e5s.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpywxd6e5s.wav
2025-07-26 06:59:36 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 06:59:41 - utils.audio_utils - INFO - Audio loaded successfully: 77760 samples, 16000Hz
2025-07-26 06:59:42 - utils.audio_utils - INFO - Audio preprocessed: 2048 samples
2025-07-26 06:59:42 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 06:59:43 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-26 06:59:43 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 06:59:43 - services.transcription_service - INFO - Model used: whisper
2025-07-26 06:59:43 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 06:59:44 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-26 07:14:22 - routes.api - INFO - Audio data decoded successfully: 29141 bytes, format: webm
2025-07-26 07:14:22 - utils.audio_utils - INFO - Loading audio: 29141 bytes, format: webm
2025-07-26 07:14:22 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:14:22 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp5u_vqa9f.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp5u_vqa9f.wav
2025-07-26 07:14:22 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:14:22 - utils.audio_utils - INFO - Audio loaded successfully: 28800 samples, 16000Hz
2025-07-26 07:14:22 - utils.audio_utils - INFO - Audio preprocessed: 28800 samples
2025-07-26 07:14:22 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:14:23 - services.transcription_service - INFO - Transcription completed: 'BAM!' (4 characters)
2025-07-26 07:14:23 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:14:23 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:14:23 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:14:23 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.360)
2025-07-26 07:14:26 - routes.api - INFO - Audio data decoded successfully: 23345 bytes, format: webm
2025-07-26 07:14:26 - utils.audio_utils - INFO - Loading audio: 23345 bytes, format: webm
2025-07-26 07:14:26 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:14:26 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpoub6e6a4.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpoub6e6a4.wav
2025-07-26 07:14:27 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:14:27 - utils.audio_utils - INFO - Audio loaded successfully: 23040 samples, 16000Hz
2025-07-26 07:14:27 - utils.audio_utils - INFO - Audio preprocessed: 23040 samples
2025-07-26 07:14:27 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:14:28 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 07:14:28 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:14:28 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:14:28 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:14:28 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 07:16:18 - routes.api - INFO - Audio data decoded successfully: 4991 bytes, format: webm
2025-07-26 07:16:18 - utils.audio_utils - INFO - Loading audio: 4991 bytes, format: webm
2025-07-26 07:16:18 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:16:18 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmplg2dlwp9.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmplg2dlwp9.wav
2025-07-26 07:16:19 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:16:19 - utils.audio_utils - INFO - Audio loaded successfully: 4800 samples, 16000Hz
2025-07-26 07:16:19 - utils.audio_utils - INFO - Audio preprocessed: 4800 samples
2025-07-26 07:16:19 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:16:19 - services.transcription_service - INFO - Transcription completed: 'BAM!' (4 characters)
2025-07-26 07:16:19 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:16:19 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:16:19 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:16:20 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.360)
2025-07-26 07:16:23 - routes.api - INFO - Audio data decoded successfully: 19481 bytes, format: webm
2025-07-26 07:16:23 - utils.audio_utils - INFO - Loading audio: 19481 bytes, format: webm
2025-07-26 07:16:23 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:16:23 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp8umgrmmz.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp8umgrmmz.wav
2025-07-26 07:16:23 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:16:23 - utils.audio_utils - INFO - Audio loaded successfully: 19200 samples, 16000Hz
2025-07-26 07:16:23 - utils.audio_utils - INFO - Audio preprocessed: 19200 samples
2025-07-26 07:16:23 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:16:24 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 07:16:24 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:16:24 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:16:24 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:16:24 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 07:16:31 - routes.api - INFO - Audio data decoded successfully: 83237 bytes, format: webm
2025-07-26 07:16:31 - utils.audio_utils - INFO - Loading audio: 83237 bytes, format: webm
2025-07-26 07:16:31 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:16:31 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpm85tzf14.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpm85tzf14.wav
2025-07-26 07:16:31 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:16:31 - utils.audio_utils - INFO - Audio loaded successfully: 82560 samples, 16000Hz
2025-07-26 07:16:31 - utils.audio_utils - INFO - Audio preprocessed: 82560 samples
2025-07-26 07:16:31 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:16:32 - services.transcription_service - INFO - Transcription completed: 'I'm going to use the same method as the other one.' (50 characters)
2025-07-26 07:16:32 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 07:16:32 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:16:32 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:16:32 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.598)
2025-07-26 07:16:38 - routes.api - INFO - Audio data decoded successfully: 29141 bytes, format: webm
2025-07-26 07:16:38 - utils.audio_utils - INFO - Loading audio: 29141 bytes, format: webm
2025-07-26 07:16:38 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:16:38 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpe7cxmb_4.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpe7cxmb_4.wav
2025-07-26 07:16:39 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:16:39 - utils.audio_utils - INFO - Audio loaded successfully: 28800 samples, 16000Hz
2025-07-26 07:16:39 - utils.audio_utils - INFO - Audio preprocessed: 28800 samples
2025-07-26 07:16:39 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:16:39 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 07:16:39 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:16:39 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:16:39 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:16:39 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 07:20:41 - routes.api - INFO - Audio data decoded successfully: 6923 bytes, format: webm
2025-07-26 07:20:41 - utils.audio_utils - INFO - Loading audio: 6923 bytes, format: webm
2025-07-26 07:20:41 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:20:41 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp3t19aiev.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp3t19aiev.wav
2025-07-26 07:20:41 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:20:41 - utils.audio_utils - INFO - Audio loaded successfully: 6720 samples, 16000Hz
2025-07-26 07:20:41 - utils.audio_utils - INFO - Audio preprocessed: 6720 samples
2025-07-26 07:20:41 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:20:42 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 07:20:42 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 07:20:42 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:20:42 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:20:42 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 07:20:45 - routes.api - INFO - Audio data decoded successfully: 9821 bytes, format: webm
2025-07-26 07:20:45 - utils.audio_utils - INFO - Loading audio: 9821 bytes, format: webm
2025-07-26 07:20:45 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:20:45 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp2qzmz6f0.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp2qzmz6f0.wav
2025-07-26 07:20:46 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:20:46 - utils.audio_utils - INFO - Audio loaded successfully: 9600 samples, 16000Hz
2025-07-26 07:20:46 - utils.audio_utils - INFO - Audio preprocessed: 9600 samples
2025-07-26 07:20:46 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:20:46 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 07:20:46 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 07:20:46 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:20:46 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:20:47 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 07:21:18 - routes.api - INFO - Audio data decoded successfully: 16583 bytes, format: webm
2025-07-26 07:21:18 - utils.audio_utils - INFO - Loading audio: 16583 bytes, format: webm
2025-07-26 07:21:18 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:21:18 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpn_tu_pzn.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpn_tu_pzn.wav
2025-07-26 07:21:18 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:21:18 - utils.audio_utils - INFO - Audio loaded successfully: 16320 samples, 16000Hz
2025-07-26 07:21:18 - utils.audio_utils - INFO - Audio preprocessed: 16320 samples
2025-07-26 07:21:18 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:21:19 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 07:21:19 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 07:21:19 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:21:19 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:21:19 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 07:22:17 - routes.api - INFO - Audio data decoded successfully: 15617 bytes, format: webm
2025-07-26 07:22:17 - utils.audio_utils - INFO - Loading audio: 15617 bytes, format: webm
2025-07-26 07:22:17 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:22:17 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmptdzpvrty.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmptdzpvrty.wav
2025-07-26 07:22:17 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:22:17 - utils.audio_utils - INFO - Audio loaded successfully: 15360 samples, 16000Hz
2025-07-26 07:22:17 - utils.audio_utils - INFO - Audio preprocessed: 15360 samples
2025-07-26 07:22:17 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:22:18 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-26 07:22:18 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:22:18 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:22:18 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:22:18 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-26 07:24:14 - routes.api - INFO - Audio data decoded successfully: 14651 bytes, format: webm
2025-07-26 07:24:14 - utils.audio_utils - INFO - Loading audio: 14651 bytes, format: webm
2025-07-26 07:24:14 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:24:14 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpf2t71vuo.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpf2t71vuo.wav
2025-07-26 07:24:14 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:24:14 - utils.audio_utils - INFO - Audio loaded successfully: 14400 samples, 16000Hz
2025-07-26 07:24:14 - utils.audio_utils - INFO - Audio preprocessed: 14400 samples
2025-07-26 07:24:14 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:24:15 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-26 07:24:15 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:24:15 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:24:15 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:24:15 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-26 07:24:18 - routes.api - INFO - Audio data decoded successfully: 22379 bytes, format: webm
2025-07-26 07:24:18 - utils.audio_utils - INFO - Loading audio: 22379 bytes, format: webm
2025-07-26 07:24:18 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:24:18 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp__9j9hqd.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp__9j9hqd.wav
2025-07-26 07:24:18 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:24:18 - utils.audio_utils - INFO - Audio loaded successfully: 22080 samples, 16000Hz
2025-07-26 07:24:18 - utils.audio_utils - INFO - Audio preprocessed: 22080 samples
2025-07-26 07:24:18 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:24:19 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 07:24:19 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:24:19 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:24:19 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:24:19 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 07:31:06 - routes.api - INFO - Audio data decoded successfully: 28175 bytes, format: webm
2025-07-26 07:31:06 - utils.audio_utils - INFO - Loading audio: 28175 bytes, format: webm
2025-07-26 07:31:06 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:31:06 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpqhdkm304.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpqhdkm304.wav
2025-07-26 07:31:06 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:31:06 - utils.audio_utils - INFO - Audio loaded successfully: 27840 samples, 16000Hz
2025-07-26 07:31:06 - utils.audio_utils - INFO - Audio preprocessed: 27840 samples
2025-07-26 07:31:06 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:31:07 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 07:31:07 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:31:07 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:31:07 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:31:07 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 07:31:11 - routes.api - INFO - Audio data decoded successfully: 10787 bytes, format: webm
2025-07-26 07:31:11 - utils.audio_utils - INFO - Loading audio: 10787 bytes, format: webm
2025-07-26 07:31:11 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:31:11 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpf9ndwleg.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpf9ndwleg.wav
2025-07-26 07:31:11 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:31:11 - utils.audio_utils - INFO - Audio loaded successfully: 10560 samples, 16000Hz
2025-07-26 07:31:11 - utils.audio_utils - INFO - Audio preprocessed: 10560 samples
2025-07-26 07:31:11 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:31:12 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 07:31:12 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 07:31:12 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:31:12 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:31:12 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 07:31:18 - routes.api - INFO - Audio data decoded successfully: 42665 bytes, format: webm
2025-07-26 07:31:18 - utils.audio_utils - INFO - Loading audio: 42665 bytes, format: webm
2025-07-26 07:31:18 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:31:18 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpvz111shg.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpvz111shg.wav
2025-07-26 07:31:18 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:31:18 - utils.audio_utils - INFO - Audio loaded successfully: 42240 samples, 16000Hz
2025-07-26 07:31:18 - utils.audio_utils - INFO - Audio preprocessed: 42240 samples
2025-07-26 07:31:18 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:31:19 - services.transcription_service - INFO - Transcription completed: 'I'm gonna have to go to the bathroom.' (37 characters)
2025-07-26 07:31:19 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 07:31:19 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:31:19 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:31:19 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.883)
2025-07-26 07:38:57 - routes.api - INFO - Audio data decoded successfully: 9821 bytes, format: webm
2025-07-26 07:38:57 - utils.audio_utils - INFO - Loading audio: 9821 bytes, format: webm
2025-07-26 07:38:57 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:38:57 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpyqr022fi.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpyqr022fi.wav
2025-07-26 07:38:57 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:38:57 - utils.audio_utils - INFO - Audio loaded successfully: 9600 samples, 16000Hz
2025-07-26 07:38:57 - utils.audio_utils - INFO - Audio preprocessed: 9600 samples
2025-07-26 07:38:57 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:38:58 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 07:38:58 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 07:38:58 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:38:58 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:38:58 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 07:49:10 - routes.api - INFO - Audio data decoded successfully: 22379 bytes, format: webm
2025-07-26 07:49:10 - utils.audio_utils - INFO - Loading audio: 22379 bytes, format: webm
2025-07-26 07:49:10 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:49:10 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpxthu96rh.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpxthu96rh.wav
2025-07-26 07:49:10 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:49:10 - utils.audio_utils - INFO - Audio loaded successfully: 22080 samples, 16000Hz
2025-07-26 07:49:10 - utils.audio_utils - INFO - Audio preprocessed: 22080 samples
2025-07-26 07:49:10 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:49:11 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 07:49:11 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:49:11 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:49:11 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:49:11 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 07:49:25 - routes.api - INFO - Audio data decoded successfully: 18515 bytes, format: webm
2025-07-26 07:49:25 - utils.audio_utils - INFO - Loading audio: 18515 bytes, format: webm
2025-07-26 07:49:25 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:49:25 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpfxx_lg7v.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpfxx_lg7v.wav
2025-07-26 07:49:25 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:49:25 - utils.audio_utils - INFO - Audio loaded successfully: 18240 samples, 16000Hz
2025-07-26 07:49:25 - utils.audio_utils - INFO - Audio preprocessed: 18240 samples
2025-07-26 07:49:25 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:49:26 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 07:49:26 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 07:49:26 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:49:26 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:49:26 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 07:54:48 - routes.api - INFO - Audio data decoded successfully: 24311 bytes, format: webm
2025-07-26 07:54:48 - utils.audio_utils - INFO - Loading audio: 24311 bytes, format: webm
2025-07-26 07:54:48 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 07:54:48 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpwh2xqpez.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpwh2xqpez.wav
2025-07-26 07:54:48 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 07:54:48 - utils.audio_utils - INFO - Audio loaded successfully: 24000 samples, 16000Hz
2025-07-26 07:54:48 - utils.audio_utils - INFO - Audio preprocessed: 24000 samples
2025-07-26 07:54:48 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 07:54:49 - services.transcription_service - INFO - Transcription completed: 'I'm gonna get the fuck out of here.' (35 characters)
2025-07-26 07:54:49 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 07:54:49 - services.transcription_service - INFO - Model used: whisper
2025-07-26 07:54:49 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 07:54:49 - services.emotion_service - INFO - Text emotion detected: angry (confidence: 0.834)
2025-07-26 08:02:19 - routes.api - INFO - Audio data decoded successfully: 13685 bytes, format: webm
2025-07-26 08:02:19 - utils.audio_utils - INFO - Loading audio: 13685 bytes, format: webm
2025-07-26 08:02:19 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:02:19 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp8ydf8ul2.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp8ydf8ul2.wav
2025-07-26 08:02:19 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:02:19 - utils.audio_utils - INFO - Audio loaded successfully: 13440 samples, 16000Hz
2025-07-26 08:02:19 - utils.audio_utils - INFO - Audio preprocessed: 13440 samples
2025-07-26 08:02:19 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:02:21 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 08:02:21 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 08:02:21 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:02:21 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:02:21 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 08:02:25 - routes.api - INFO - Audio data decoded successfully: 9821 bytes, format: webm
2025-07-26 08:02:25 - utils.audio_utils - INFO - Loading audio: 9821 bytes, format: webm
2025-07-26 08:02:25 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:02:25 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpvrw6en7h.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpvrw6en7h.wav
2025-07-26 08:02:26 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:02:26 - utils.audio_utils - INFO - Audio loaded successfully: 9600 samples, 16000Hz
2025-07-26 08:02:26 - utils.audio_utils - INFO - Audio preprocessed: 9600 samples
2025-07-26 08:02:26 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:02:26 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 08:02:26 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 08:02:26 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:02:26 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:02:26 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 08:07:55 - routes.api - INFO - Audio data decoded successfully: 15617 bytes, format: webm
2025-07-26 08:07:55 - utils.audio_utils - INFO - Loading audio: 15617 bytes, format: webm
2025-07-26 08:07:55 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:07:55 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpxfs8kpsh.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpxfs8kpsh.wav
2025-07-26 08:07:55 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:07:55 - utils.audio_utils - INFO - Audio loaded successfully: 15360 samples, 16000Hz
2025-07-26 08:07:55 - utils.audio_utils - INFO - Audio preprocessed: 15360 samples
2025-07-26 08:07:55 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:07:56 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-26 08:07:56 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 08:07:56 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:07:56 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:07:56 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-26 08:09:16 - routes.api - INFO - Audio data decoded successfully: 9821 bytes, format: webm
2025-07-26 08:09:16 - utils.audio_utils - INFO - Loading audio: 9821 bytes, format: webm
2025-07-26 08:09:16 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:09:16 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmposqx8jvo.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmposqx8jvo.wav
2025-07-26 08:09:16 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:09:16 - utils.audio_utils - INFO - Audio loaded successfully: 9600 samples, 16000Hz
2025-07-26 08:09:16 - utils.audio_utils - INFO - Audio preprocessed: 9600 samples
2025-07-26 08:09:16 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:09:17 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 08:09:17 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 08:09:17 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:09:17 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:09:17 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 08:12:31 - routes.api - INFO - Audio data decoded successfully: 187565 bytes, format: webm
2025-07-26 08:12:31 - utils.audio_utils - INFO - Loading audio: 187565 bytes, format: webm
2025-07-26 08:12:31 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:12:31 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpog_76xcq.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpog_76xcq.wav
2025-07-26 08:12:31 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:12:31 - utils.audio_utils - INFO - Audio loaded successfully: 186240 samples, 16000Hz
2025-07-26 08:12:31 - utils.audio_utils - INFO - Audio preprocessed: 186240 samples
2025-07-26 08:12:31 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:12:32 - services.transcription_service - INFO - Transcription completed: 'I'm going to use the same method as the other side.' (51 characters)
2025-07-26 08:12:32 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 08:12:32 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:12:32 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:12:32 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.550)
2025-07-26 08:12:45 - routes.api - INFO - Audio data decoded successfully: 12719 bytes, format: webm
2025-07-26 08:12:45 - utils.audio_utils - INFO - Loading audio: 12719 bytes, format: webm
2025-07-26 08:12:45 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:12:45 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpdf09b8uq.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpdf09b8uq.wav
2025-07-26 08:12:45 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:12:45 - utils.audio_utils - INFO - Audio loaded successfully: 12480 samples, 16000Hz
2025-07-26 08:12:45 - utils.audio_utils - INFO - Audio preprocessed: 12480 samples
2025-07-26 08:12:45 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:12:46 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 08:12:46 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 08:12:46 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:12:46 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:12:46 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 08:12:48 - routes.api - INFO - Audio data decoded successfully: 13685 bytes, format: webm
2025-07-26 08:12:48 - utils.audio_utils - INFO - Loading audio: 13685 bytes, format: webm
2025-07-26 08:12:48 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:12:48 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpbd1e_hrj.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpbd1e_hrj.wav
2025-07-26 08:12:49 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:12:49 - utils.audio_utils - INFO - Audio loaded successfully: 13440 samples, 16000Hz
2025-07-26 08:12:49 - utils.audio_utils - INFO - Audio preprocessed: 13440 samples
2025-07-26 08:12:49 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:12:50 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 08:12:50 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 08:12:50 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:12:50 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:12:50 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 08:20:02 - routes.api - INFO - Audio data decoded successfully: 542103 bytes, format: webm
2025-07-26 08:20:02 - utils.audio_utils - INFO - Loading audio: 542103 bytes, format: webm
2025-07-26 08:20:02 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:20:02 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpksck1gr_.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpksck1gr_.wav
2025-07-26 08:20:03 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:20:03 - utils.audio_utils - INFO - Audio loaded successfully: 538560 samples, 16000Hz
2025-07-26 08:20:03 - utils.audio_utils - INFO - Audio preprocessed: 504832 samples
2025-07-26 08:20:03 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:20:05 - services.transcription_service - INFO - Transcription completed: 'I wonder what happens if you add a really, really, really long paragraphs. So I'm just going to talk over and over and over again. And I've all done the things to talk about. So I guess we're just going to be waiting there and just yapping until this finishes. But I'll keep it going until about 820. Once it gets to 820, I'll probably stop talking. Maybe I'll go a little longer, but yeah. So it's about 820 now.' (413 characters)
2025-07-26 08:20:05 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 08:20:05 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:20:05 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:20:05 - services.emotion_service - INFO - Text emotion detected: excited (confidence: 0.225)
2025-07-26 08:21:01 - routes.api - INFO - Audio data decoded successfully: 137333 bytes, format: webm
2025-07-26 08:21:01 - utils.audio_utils - INFO - Loading audio: 137333 bytes, format: webm
2025-07-26 08:21:01 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:21:01 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp2wm2zxl_.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp2wm2zxl_.wav
2025-07-26 08:21:01 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:21:01 - utils.audio_utils - INFO - Audio loaded successfully: 136320 samples, 16000Hz
2025-07-26 08:21:01 - utils.audio_utils - INFO - Audio preprocessed: 119808 samples
2025-07-26 08:21:01 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:21:02 - services.transcription_service - INFO - Transcription completed: 'This is another normal size recording. So this is probably the standard paragraph one person.' (93 characters)
2025-07-26 08:21:02 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 08:21:02 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:21:02 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:21:02 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.757)
2025-07-26 08:25:44 - routes.api - INFO - Audio data decoded successfully: 187565 bytes, format: webm
2025-07-26 08:25:44 - utils.audio_utils - INFO - Loading audio: 187565 bytes, format: webm
2025-07-26 08:25:44 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 08:25:44 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpzoy5fjxr.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpzoy5fjxr.wav
2025-07-26 08:25:44 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 08:25:44 - utils.audio_utils - INFO - Audio loaded successfully: 186240 samples, 16000Hz
2025-07-26 08:25:45 - utils.audio_utils - INFO - Audio preprocessed: 144896 samples
2025-07-26 08:25:45 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 08:25:46 - services.transcription_service - INFO - Transcription completed: 'I was reading a book yesterday and I was surprised it was a small book, only 30 pages, but it contained like a mountain of information.' (135 characters)
2025-07-26 08:25:46 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 08:25:46 - services.transcription_service - INFO - Model used: whisper
2025-07-26 08:25:46 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 08:25:46 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.867)
2025-07-26 19:27:21 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-26 19:27:21 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-26 19:27:21 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-26 19:27:21 - services.transcription_service - INFO - Using CPU for transcription
2025-07-26 19:27:21 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-26 19:27:25 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-26 19:27:25 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-26 19:27:25 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-26 19:27:25 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-26 19:27:25 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-26 19:27:28 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-26 19:27:28 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-26 19:27:28 - app - INFO - ToneBridge Backend initialized successfully
2025-07-26 19:29:15 - routes.api - INFO - Audio data decoded successfully: 12719 bytes, format: webm
2025-07-26 19:29:15 - utils.audio_utils - INFO - Loading audio: 12719 bytes, format: webm
2025-07-26 19:29:15 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 19:29:15 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp4q_4a_d4.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp4q_4a_d4.wav
2025-07-26 19:29:15 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 19:29:20 - utils.audio_utils - INFO - Audio loaded successfully: 12480 samples, 16000Hz
2025-07-26 19:29:21 - utils.audio_utils - INFO - Audio preprocessed: 12480 samples
2025-07-26 19:29:21 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 19:29:22 - services.transcription_service - INFO - Transcription completed: 'BAM!' (4 characters)
2025-07-26 19:29:22 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 19:29:22 - services.transcription_service - INFO - Model used: whisper
2025-07-26 19:29:22 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 19:29:24 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.360)
2025-07-26 19:29:48 - routes.api - INFO - Audio data decoded successfully: 14651 bytes, format: webm
2025-07-26 19:29:48 - utils.audio_utils - INFO - Loading audio: 14651 bytes, format: webm
2025-07-26 19:29:48 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 19:29:48 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpuw_td2n7.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpuw_td2n7.wav
2025-07-26 19:29:49 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 19:29:49 - utils.audio_utils - INFO - Audio loaded successfully: 14400 samples, 16000Hz
2025-07-26 19:29:49 - utils.audio_utils - INFO - Audio preprocessed: 14400 samples
2025-07-26 19:29:49 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 19:29:50 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-26 19:29:50 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 19:29:50 - services.transcription_service - INFO - Model used: whisper
2025-07-26 19:29:50 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 19:29:50 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-26 19:29:52 - routes.api - INFO - Audio data decoded successfully: 13685 bytes, format: webm
2025-07-26 19:29:52 - utils.audio_utils - INFO - Loading audio: 13685 bytes, format: webm
2025-07-26 19:29:52 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 19:29:52 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp7tjgopcn.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp7tjgopcn.wav
2025-07-26 19:29:52 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 19:29:52 - utils.audio_utils - INFO - Audio loaded successfully: 13440 samples, 16000Hz
2025-07-26 19:29:52 - utils.audio_utils - INFO - Audio preprocessed: 13440 samples
2025-07-26 19:29:52 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 19:29:53 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 19:29:53 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 19:29:53 - services.transcription_service - INFO - Model used: whisper
2025-07-26 19:29:53 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 19:29:53 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 19:30:36 - routes.api - INFO - Audio data decoded successfully: 9821 bytes, format: webm
2025-07-26 19:30:36 - utils.audio_utils - INFO - Loading audio: 9821 bytes, format: webm
2025-07-26 19:30:36 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 19:30:36 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpetrh0sbz.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpetrh0sbz.wav
2025-07-26 19:30:36 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 19:30:36 - utils.audio_utils - INFO - Audio loaded successfully: 9600 samples, 16000Hz
2025-07-26 19:30:36 - utils.audio_utils - INFO - Audio preprocessed: 9600 samples
2025-07-26 19:30:36 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 19:30:37 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 19:30:37 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 19:30:37 - services.transcription_service - INFO - Model used: whisper
2025-07-26 19:30:37 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 19:30:37 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 21:24:29 - routes.api - INFO - Audio data decoded successfully: 13685 bytes, format: webm
2025-07-26 21:24:29 - utils.audio_utils - INFO - Loading audio: 13685 bytes, format: webm
2025-07-26 21:24:29 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 21:24:29 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpmthvg6pl.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpmthvg6pl.wav
2025-07-26 21:24:30 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 21:24:30 - utils.audio_utils - INFO - Audio loaded successfully: 13440 samples, 16000Hz
2025-07-26 21:24:30 - utils.audio_utils - INFO - Audio preprocessed: 13440 samples
2025-07-26 21:24:30 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 21:24:33 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 21:24:33 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 21:24:33 - services.transcription_service - INFO - Model used: whisper
2025-07-26 21:24:33 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 21:24:34 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 21:28:13 - routes.api - INFO - Audio data decoded successfully: 10787 bytes, format: webm
2025-07-26 21:28:13 - utils.audio_utils - INFO - Loading audio: 10787 bytes, format: webm
2025-07-26 21:28:13 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 21:28:13 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpva61388y.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpva61388y.wav
2025-07-26 21:28:13 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 21:28:13 - utils.audio_utils - INFO - Audio loaded successfully: 10560 samples, 16000Hz
2025-07-26 21:28:13 - utils.audio_utils - INFO - Audio preprocessed: 10560 samples
2025-07-26 21:28:13 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 21:28:14 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 21:28:14 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 21:28:14 - services.transcription_service - INFO - Model used: whisper
2025-07-26 21:28:14 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 21:28:14 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 21:29:12 - routes.api - INFO - Audio data decoded successfully: 9821 bytes, format: webm
2025-07-26 21:29:12 - utils.audio_utils - INFO - Loading audio: 9821 bytes, format: webm
2025-07-26 21:29:12 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 21:29:12 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp0o3o95md.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp0o3o95md.wav
2025-07-26 21:29:12 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 21:29:12 - utils.audio_utils - INFO - Audio loaded successfully: 9600 samples, 16000Hz
2025-07-26 21:29:12 - utils.audio_utils - INFO - Audio preprocessed: 9600 samples
2025-07-26 21:29:12 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 21:29:13 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 21:29:13 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 21:29:13 - services.transcription_service - INFO - Model used: whisper
2025-07-26 21:29:13 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 21:29:13 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 21:31:59 - routes.api - INFO - Audio data decoded successfully: 15617 bytes, format: webm
2025-07-26 21:31:59 - utils.audio_utils - INFO - Loading audio: 15617 bytes, format: webm
2025-07-26 21:31:59 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 21:31:59 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpavnvyyue.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpavnvyyue.wav
2025-07-26 21:31:59 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 21:31:59 - utils.audio_utils - INFO - Audio loaded successfully: 15360 samples, 16000Hz
2025-07-26 21:31:59 - utils.audio_utils - INFO - Audio preprocessed: 15360 samples
2025-07-26 21:31:59 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 21:32:00 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-26 21:32:00 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 21:32:00 - services.transcription_service - INFO - Model used: whisper
2025-07-26 21:32:00 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 21:32:00 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-26 22:01:25 - routes.api - INFO - Audio data decoded successfully: 13685 bytes, format: webm
2025-07-26 22:01:25 - utils.audio_utils - INFO - Loading audio: 13685 bytes, format: webm
2025-07-26 22:01:25 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 22:01:25 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpbwa7zfcj.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpbwa7zfcj.wav
2025-07-26 22:01:25 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 22:01:25 - utils.audio_utils - INFO - Audio loaded successfully: 13440 samples, 16000Hz
2025-07-26 22:01:25 - utils.audio_utils - INFO - Audio preprocessed: 13440 samples
2025-07-26 22:01:25 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 22:01:26 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-26 22:01:26 - services.transcription_service - INFO - Confidence: 0.7
2025-07-26 22:01:26 - services.transcription_service - INFO - Model used: whisper
2025-07-26 22:01:26 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 22:01:26 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-26 22:01:34 - routes.api - INFO - Audio data decoded successfully: 19481 bytes, format: webm
2025-07-26 22:01:34 - utils.audio_utils - INFO - Loading audio: 19481 bytes, format: webm
2025-07-26 22:01:34 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 22:01:34 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpcpth8at3.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpcpth8at3.wav
2025-07-26 22:01:35 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 22:01:35 - utils.audio_utils - INFO - Audio loaded successfully: 19200 samples, 16000Hz
2025-07-26 22:01:35 - utils.audio_utils - INFO - Audio preprocessed: 19200 samples
2025-07-26 22:01:35 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 22:01:36 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 22:01:36 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 22:01:36 - services.transcription_service - INFO - Model used: whisper
2025-07-26 22:01:36 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 22:01:36 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 22:01:41 - routes.api - INFO - Audio data decoded successfully: 23345 bytes, format: webm
2025-07-26 22:01:41 - utils.audio_utils - INFO - Loading audio: 23345 bytes, format: webm
2025-07-26 22:01:41 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 22:01:41 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp1tg1fgxq.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp1tg1fgxq.wav
2025-07-26 22:01:41 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 22:01:41 - utils.audio_utils - INFO - Audio loaded successfully: 23040 samples, 16000Hz
2025-07-26 22:01:41 - utils.audio_utils - INFO - Audio preprocessed: 23040 samples
2025-07-26 22:01:41 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 22:01:42 - services.transcription_service - INFO - Transcription completed: 'I' (1 characters)
2025-07-26 22:01:42 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 22:01:42 - services.transcription_service - INFO - Model used: whisper
2025-07-26 22:01:42 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 22:01:42 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-07-26 22:40:12 - routes.api - INFO - Audio data decoded successfully: 163415 bytes, format: webm
2025-07-26 22:40:12 - utils.audio_utils - INFO - Loading audio: 163415 bytes, format: webm
2025-07-26 22:40:12 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 22:40:12 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp_qwf6rfh.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp_qwf6rfh.wav
2025-07-26 22:40:12 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 22:40:12 - utils.audio_utils - INFO - Audio loaded successfully: 162240 samples, 16000Hz
2025-07-26 22:40:12 - utils.audio_utils - INFO - Audio preprocessed: 162240 samples
2025-07-26 22:40:12 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 22:40:13 - services.transcription_service - INFO - Transcription completed: 'I'm going to use the same method as the other side.' (51 characters)
2025-07-26 22:40:13 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 22:40:13 - services.transcription_service - INFO - Model used: whisper
2025-07-26 22:40:13 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 22:40:13 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.550)
2025-07-26 22:55:50 - routes.api - INFO - Audio data decoded successfully: 27209 bytes, format: webm
2025-07-26 22:55:50 - utils.audio_utils - INFO - Loading audio: 27209 bytes, format: webm
2025-07-26 22:55:50 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 22:55:50 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp2g3wscke.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp2g3wscke.wav
2025-07-26 22:55:50 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 22:55:50 - utils.audio_utils - INFO - Audio loaded successfully: 26880 samples, 16000Hz
2025-07-26 22:55:50 - utils.audio_utils - INFO - Audio preprocessed: 26880 samples
2025-07-26 22:55:50 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 22:55:51 - services.transcription_service - INFO - Transcription completed: 'I'm gonna get the gun.' (22 characters)
2025-07-26 22:55:51 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 22:55:51 - services.transcription_service - INFO - Model used: whisper
2025-07-26 22:55:51 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 22:55:52 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.899)
2025-07-26 23:05:27 - routes.api - INFO - Audio data decoded successfully: 14651 bytes, format: webm
2025-07-26 23:05:27 - utils.audio_utils - INFO - Loading audio: 14651 bytes, format: webm
2025-07-26 23:05:27 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 23:05:27 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpyz1x4crl.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpyz1x4crl.wav
2025-07-26 23:05:27 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 23:05:27 - utils.audio_utils - INFO - Audio loaded successfully: 14400 samples, 16000Hz
2025-07-26 23:05:27 - utils.audio_utils - INFO - Audio preprocessed: 14400 samples
2025-07-26 23:05:27 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 23:05:28 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-26 23:05:28 - services.transcription_service - INFO - Confidence: 0.5
2025-07-26 23:05:28 - services.transcription_service - INFO - Model used: whisper
2025-07-26 23:05:28 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 23:05:28 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-26 23:05:33 - routes.api - INFO - Audio data decoded successfully: 53291 bytes, format: webm
2025-07-26 23:05:33 - utils.audio_utils - INFO - Loading audio: 53291 bytes, format: webm
2025-07-26 23:05:33 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-26 23:05:33 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpa1ypboya.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpa1ypboya.wav
2025-07-26 23:05:33 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-26 23:05:33 - utils.audio_utils - INFO - Audio loaded successfully: 52800 samples, 16000Hz
2025-07-26 23:05:33 - utils.audio_utils - INFO - Audio preprocessed: 52800 samples
2025-07-26 23:05:33 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-26 23:05:34 - services.transcription_service - INFO - Transcription completed: 'I'm going to use the same thing as the other one.' (49 characters)
2025-07-26 23:05:34 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-26 23:05:34 - services.transcription_service - INFO - Model used: whisper
2025-07-26 23:05:34 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-26 23:05:34 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.698)
2025-07-27 08:44:55 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-27 08:44:55 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-27 08:44:55 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-27 08:44:55 - services.transcription_service - INFO - Using CPU for transcription
2025-07-27 08:44:55 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-27 08:44:59 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-27 08:44:59 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-27 08:44:59 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-27 08:44:59 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-27 08:44:59 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-27 08:45:01 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-27 08:45:01 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-27 08:45:01 - app - INFO - ToneBridge Backend initialized successfully
2025-07-27 09:11:48 - routes.api - INFO - Audio data decoded successfully: 8855 bytes, format: webm
2025-07-27 09:11:48 - utils.audio_utils - INFO - Loading audio: 8855 bytes, format: webm
2025-07-27 09:11:48 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-27 09:11:48 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp9b6lled7.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp9b6lled7.wav
2025-07-27 09:11:48 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-27 09:11:53 - utils.audio_utils - INFO - Audio loaded successfully: 8640 samples, 16000Hz
2025-07-27 09:11:54 - utils.audio_utils - INFO - Audio preprocessed: 8640 samples
2025-07-27 09:11:54 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-27 09:11:55 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-27 09:11:55 - services.transcription_service - INFO - Confidence: 0.7
2025-07-27 09:11:55 - services.transcription_service - INFO - Model used: whisper
2025-07-27 09:11:55 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-27 09:11:57 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-27 10:27:39 - routes.api - INFO - Audio data decoded successfully: 15617 bytes, format: webm
2025-07-27 10:27:39 - utils.audio_utils - INFO - Loading audio: 15617 bytes, format: webm
2025-07-27 10:27:39 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-27 10:27:39 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp3u2uedl2.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp3u2uedl2.wav
2025-07-27 10:27:39 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-27 10:27:39 - utils.audio_utils - INFO - Audio loaded successfully: 15360 samples, 16000Hz
2025-07-27 10:27:39 - utils.audio_utils - INFO - Audio preprocessed: 15360 samples
2025-07-27 10:27:39 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-27 10:27:41 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-27 10:27:41 - services.transcription_service - INFO - Confidence: 0.5
2025-07-27 10:27:41 - services.transcription_service - INFO - Model used: whisper
2025-07-27 10:27:41 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-27 10:27:41 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-27 10:30:04 - routes.api - INFO - Audio data decoded successfully: 15617 bytes, format: webm
2025-07-27 10:30:04 - utils.audio_utils - INFO - Loading audio: 15617 bytes, format: webm
2025-07-27 10:30:04 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-27 10:30:04 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpcitgc0wo.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpcitgc0wo.wav
2025-07-27 10:30:04 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-27 10:30:04 - utils.audio_utils - INFO - Audio loaded successfully: 15360 samples, 16000Hz
2025-07-27 10:30:04 - utils.audio_utils - INFO - Audio preprocessed: 15360 samples
2025-07-27 10:30:04 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-27 10:30:05 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-27 10:30:05 - services.transcription_service - INFO - Confidence: 0.5
2025-07-27 10:30:05 - services.transcription_service - INFO - Model used: whisper
2025-07-27 10:30:05 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-27 10:30:05 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-27 10:33:00 - routes.api - INFO - Audio data decoded successfully: 15617 bytes, format: webm
2025-07-27 10:33:00 - utils.audio_utils - INFO - Loading audio: 15617 bytes, format: webm
2025-07-27 10:33:00 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-27 10:33:00 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpuwrtemb_.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpuwrtemb_.wav
2025-07-27 10:33:01 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-27 10:33:01 - utils.audio_utils - INFO - Audio loaded successfully: 15360 samples, 16000Hz
2025-07-27 10:33:01 - utils.audio_utils - INFO - Audio preprocessed: 15360 samples
2025-07-27 10:33:01 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-27 10:33:02 - services.transcription_service - INFO - Transcription completed: 'Oh' (2 characters)
2025-07-27 10:33:02 - services.transcription_service - INFO - Confidence: 0.5
2025-07-27 10:33:02 - services.transcription_service - INFO - Model used: whisper
2025-07-27 10:33:02 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-27 10:33:02 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.942)
2025-07-27 10:33:04 - routes.api - INFO - Audio data decoded successfully: 12719 bytes, format: webm
2025-07-27 10:33:04 - utils.audio_utils - INFO - Loading audio: 12719 bytes, format: webm
2025-07-27 10:33:04 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-27 10:33:04 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp06yuucg8.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp06yuucg8.wav
2025-07-27 10:33:04 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-27 10:33:04 - utils.audio_utils - INFO - Audio loaded successfully: 12480 samples, 16000Hz
2025-07-27 10:33:04 - utils.audio_utils - INFO - Audio preprocessed: 12480 samples
2025-07-27 10:33:04 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-27 10:33:06 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-27 10:33:06 - services.transcription_service - INFO - Confidence: 0.7
2025-07-27 10:33:06 - services.transcription_service - INFO - Model used: whisper
2025-07-27 10:33:06 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-27 10:33:06 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-27 10:33:50 - routes.api - INFO - Audio data decoded successfully: 16583 bytes, format: webm
2025-07-27 10:33:50 - utils.audio_utils - INFO - Loading audio: 16583 bytes, format: webm
2025-07-27 10:33:50 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-27 10:33:50 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpa5m2_5cn.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpa5m2_5cn.wav
2025-07-27 10:33:50 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-27 10:33:50 - utils.audio_utils - INFO - Audio loaded successfully: 16320 samples, 16000Hz
2025-07-27 10:33:50 - utils.audio_utils - INFO - Audio preprocessed: 16320 samples
2025-07-27 10:33:50 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-27 10:33:52 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-27 10:33:52 - services.transcription_service - INFO - Confidence: 0.7
2025-07-27 10:33:52 - services.transcription_service - INFO - Model used: whisper
2025-07-27 10:33:52 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-27 10:33:52 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-27 10:34:41 - routes.api - INFO - Audio data decoded successfully: 12719 bytes, format: webm
2025-07-27 10:34:41 - utils.audio_utils - INFO - Loading audio: 12719 bytes, format: webm
2025-07-27 10:34:41 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-27 10:34:41 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpkwfco27_.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpkwfco27_.wav
2025-07-27 10:34:42 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-27 10:34:42 - utils.audio_utils - INFO - Audio loaded successfully: 12480 samples, 16000Hz
2025-07-27 10:34:42 - utils.audio_utils - INFO - Audio preprocessed: 12480 samples
2025-07-27 10:34:42 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-27 10:34:42 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-27 10:34:42 - services.transcription_service - INFO - Confidence: 0.7
2025-07-27 10:34:42 - services.transcription_service - INFO - Model used: whisper
2025-07-27 10:34:42 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-27 10:34:43 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-29 12:17:33 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:17:33 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:17:33 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:17:33 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:17:33 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:17:37 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:17:37 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:17:37 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:17:37 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:17:37 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:17:39 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:17:39 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:17:39 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:17:44 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:17:44 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:17:44 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:17:44 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:17:44 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:17:47 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:17:47 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:17:47 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:17:47 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:17:47 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:17:48 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:17:48 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:17:48 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:17:59 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:17:59 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:17:59 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:17:59 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:17:59 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:18:02 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:18:02 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:18:02 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:18:02 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:18:02 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:18:03 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:18:03 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:18:03 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:18:10 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:18:10 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:18:10 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:18:10 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:18:10 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:18:13 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:18:13 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:18:13 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:18:13 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:18:13 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:18:14 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:18:14 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:18:14 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:21:55 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:21:55 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:21:55 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:21:55 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:21:55 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:21:58 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:21:58 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:21:58 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:21:58 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:21:58 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:21:59 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:21:59 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:21:59 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:28:07 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:28:07 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:28:07 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:28:07 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:28:07 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:28:10 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:28:10 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:28:10 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:28:10 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:28:10 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:28:11 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:28:11 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:28:11 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:29:27 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:29:27 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:29:27 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:29:27 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:29:27 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:29:30 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:29:30 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:29:30 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:29:30 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:29:30 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:29:32 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:29:32 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:29:32 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:30:00 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:30:00 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:30:00 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:30:00 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:30:00 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:30:03 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:30:03 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:30:03 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:30:03 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:30:03 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:30:04 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:30:04 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:30:04 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:30:09 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:30:09 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:30:09 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:30:09 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:30:09 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:30:12 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:30:12 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:30:12 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:30:12 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:30:12 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:30:13 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:30:13 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:30:13 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:30:15 - routes.api - INFO - Audio data decoded successfully: 37835 bytes, format: webm
2025-07-29 12:30:15 - utils.audio_utils - INFO - Loading audio: 37835 bytes, format: webm
2025-07-29 12:30:15 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-29 12:30:15 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpvgka9g7l.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpvgka9g7l.wav
2025-07-29 12:30:15 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-29 12:30:20 - utils.audio_utils - INFO - Audio loaded successfully: 37440 samples, 16000Hz
2025-07-29 12:30:21 - utils.audio_utils - INFO - Audio preprocessed: 6656 samples
2025-07-29 12:30:21 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-29 12:30:22 - services.transcription_service - INFO - Transcription completed: 'Thank you.' (10 characters)
2025-07-29 12:30:22 - services.transcription_service - INFO - Confidence: 0.7
2025-07-29 12:30:22 - services.transcription_service - INFO - Model used: whisper
2025-07-29 12:30:22 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-29 12:30:24 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.990)
2025-07-29 12:43:32 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:43:32 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:43:32 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:43:32 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:43:32 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:43:34 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:43:34 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:43:34 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:43:34 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:43:34 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:43:36 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:43:36 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:43:36 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:43:41 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:43:41 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:43:41 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:43:41 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:43:41 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:43:43 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:43:43 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:43:43 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:43:43 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:43:43 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:43:45 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:43:45 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:43:45 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:45:33 - utils.error_handlers - ERROR - Unexpected Error: cannot access local variable 'time' where it is not associated with a value
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 332, in text_to_speech
    start_time = time.time()
                 ^^^^
UnboundLocalError: cannot access local variable 'time' where it is not associated with a value
2025-07-29 12:46:52 - routes.api - INFO - Audio data decoded successfully: 14651 bytes, format: webm
2025-07-29 12:46:52 - utils.audio_utils - INFO - Loading audio: 14651 bytes, format: webm
2025-07-29 12:46:52 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-29 12:46:52 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpdd2ep6iy.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpdd2ep6iy.wav
2025-07-29 12:46:52 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-29 12:46:52 - utils.audio_utils - INFO - Audio loaded successfully: 14400 samples, 16000Hz
2025-07-29 12:46:52 - utils.audio_utils - INFO - Audio preprocessed: 2048 samples
2025-07-29 12:46:52 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-29 12:46:53 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-29 12:46:53 - services.transcription_service - INFO - Confidence: 0.5
2025-07-29 12:46:53 - services.transcription_service - INFO - Model used: whisper
2025-07-29 12:46:53 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-29 12:46:53 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-29 12:46:58 - routes.api - INFO - Audio data decoded successfully: 47495 bytes, format: webm
2025-07-29 12:46:58 - utils.audio_utils - INFO - Loading audio: 47495 bytes, format: webm
2025-07-29 12:46:58 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-29 12:46:58 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp8ouj7zzp.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp8ouj7zzp.wav
2025-07-29 12:46:58 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-29 12:46:58 - utils.audio_utils - INFO - Audio loaded successfully: 47040 samples, 16000Hz
2025-07-29 12:46:58 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-07-29 12:46:58 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-29 12:46:59 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-29 12:46:59 - services.transcription_service - INFO - Confidence: 0.5
2025-07-29 12:46:59 - services.transcription_service - INFO - Model used: whisper
2025-07-29 12:46:59 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-29 12:46:59 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-29 12:53:08 - utils.error_handlers - ERROR - Unexpected Error: cannot access local variable 'time' where it is not associated with a value
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 332, in text_to_speech
    start_time = time.time()
                 ^^^^
UnboundLocalError: cannot access local variable 'time' where it is not associated with a value
2025-07-29 12:55:09 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:55:09 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:55:09 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:55:09 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:55:09 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:55:11 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:55:11 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:55:11 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:55:11 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:55:11 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:55:12 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:55:12 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:55:12 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:55:18 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:55:18 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:55:18 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:55:18 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:55:18 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:55:20 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:55:20 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:55:20 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:55:20 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:55:20 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:55:21 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:55:21 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:55:21 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:56:43 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:56:43 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:56:43 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:56:43 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:56:43 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:56:46 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:56:46 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:56:46 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:56:46 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:56:46 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:56:47 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:56:47 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:56:47 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 12:56:52 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 12:56:52 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 12:56:52 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 12:56:52 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 12:56:52 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 12:56:55 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 12:56:55 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 12:56:55 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 12:56:55 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 12:56:55 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 12:56:56 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 12:56:56 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 12:56:56 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:07:47 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:07:47 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:07:47 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:07:47 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:07:47 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:07:49 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:07:49 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:07:49 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:07:49 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:07:49 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:07:51 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:07:51 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:07:51 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:07:56 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:07:56 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:07:56 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:07:56 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:07:56 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:07:59 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:07:59 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:07:59 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:07:59 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:07:59 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:08:00 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:08:00 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:08:00 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:08:24 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:08:24 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:08:24 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:08:24 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:08:24 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:08:27 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:08:27 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:08:27 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:08:27 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:08:27 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:08:29 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:08:29 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:08:29 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:08:34 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:08:34 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:08:34 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:08:34 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:08:34 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:08:40 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:08:40 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:08:40 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:08:40 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:08:40 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:08:41 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:08:41 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:08:41 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:10:02 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:10:02 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:10:02 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:10:02 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:10:02 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:10:05 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:10:05 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:10:05 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:10:05 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:10:05 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:10:06 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:10:06 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:10:06 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:10:11 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:10:11 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:10:11 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:10:11 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:10:11 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:10:14 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:10:14 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:10:14 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:10:14 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:10:14 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:10:16 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:10:16 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:10:16 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:15:34 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:15:34 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:15:34 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:15:34 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:15:34 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:15:37 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:15:37 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:15:37 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:15:37 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:15:37 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:15:39 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:15:39 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:15:39 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:15:44 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:15:44 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:15:44 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:15:44 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:15:44 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:36:52 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:36:52 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:36:52 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:36:52 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:36:52 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:36:55 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:36:55 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:36:55 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:36:55 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:36:55 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:36:56 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:36:56 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:36:56 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:37:01 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:37:01 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:37:01 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:37:01 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:37:01 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:37:04 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:37:04 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:37:04 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:37:04 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:37:04 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:37:05 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:37:05 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:37:05 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:43:11 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:43:11 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:43:11 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:43:11 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:43:11 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:43:13 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:43:13 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:43:13 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:43:13 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:43:13 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:43:15 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:43:15 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:43:15 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 13:43:20 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 13:43:20 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 13:43:20 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 13:43:20 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 13:43:20 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 13:43:22 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 13:43:22 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 13:43:22 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 13:43:22 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 13:43:22 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 13:43:24 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 13:43:24 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 13:43:24 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 14:08:22 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 14:08:22 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 14:08:22 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 14:08:22 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 14:08:22 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 14:08:25 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 14:08:25 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 14:08:25 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 14:08:25 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 14:08:25 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 14:08:27 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 14:08:27 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 14:08:27 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 14:08:32 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 14:08:32 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 14:08:32 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 14:08:32 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 14:08:32 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 14:08:34 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 14:08:34 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 14:08:34 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 14:08:34 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 14:08:34 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 14:08:36 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 14:08:36 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 14:08:36 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 14:12:43 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 14:12:43 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 14:12:43 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 14:12:43 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 14:12:43 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 14:12:46 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 14:12:46 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 14:12:46 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 14:12:46 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 14:12:46 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 14:12:48 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 14:12:48 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 14:12:48 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 14:13:33 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 14:13:33 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 14:13:33 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 14:13:33 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 14:13:33 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 14:13:36 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 14:13:36 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 14:13:36 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 14:13:36 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 14:13:36 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 14:13:37 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 14:13:37 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 14:13:37 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 14:13:53 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 14:13:53 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 14:13:53 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 14:13:53 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 14:13:53 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 14:13:56 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 14:13:56 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 14:13:56 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 14:13:56 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 14:13:56 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 14:13:58 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 14:13:58 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 14:13:58 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 14:14:04 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-29 14:14:04 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-29 14:14:04 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-29 14:14:04 - services.transcription_service - INFO - Using CPU for transcription
2025-07-29 14:14:04 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-29 14:14:06 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-29 14:14:06 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-29 14:14:06 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-29 14:14:06 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-29 14:14:06 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-29 14:14:07 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-29 14:14:07 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-29 14:14:07 - app - INFO - ToneBridge Backend initialized successfully
2025-07-29 14:14:12 - routes.api - INFO - Audio data decoded successfully: 49427 bytes, format: webm
2025-07-29 14:14:12 - utils.audio_utils - INFO - Loading audio: 49427 bytes, format: webm
2025-07-29 14:14:12 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-29 14:14:12 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp_rcff331.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp_rcff331.wav
2025-07-29 14:14:12 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-29 14:14:17 - utils.audio_utils - INFO - Audio loaded successfully: 48960 samples, 16000Hz
2025-07-29 14:14:18 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-07-29 14:14:18 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-29 14:14:19 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-29 14:14:19 - services.transcription_service - INFO - Confidence: 0.5
2025-07-29 14:14:19 - services.transcription_service - INFO - Model used: whisper
2025-07-29 14:14:19 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-29 14:14:21 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-29 14:14:32 - utils.error_handlers - ERROR - Unexpected Error: cannot access local variable 'time' where it is not associated with a value
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 332, in text_to_speech
    start_time = time.time()
                 ^^^^
UnboundLocalError: cannot access local variable 'time' where it is not associated with a value
2025-07-29 14:14:44 - utils.error_handlers - ERROR - Unexpected Error: cannot access local variable 'time' where it is not associated with a value
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 332, in text_to_speech
    start_time = time.time()
                 ^^^^
UnboundLocalError: cannot access local variable 'time' where it is not associated with a value
2025-07-29 14:14:45 - utils.error_handlers - ERROR - Unexpected Error: cannot access local variable 'time' where it is not associated with a value
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 332, in text_to_speech
    start_time = time.time()
                 ^^^^
UnboundLocalError: cannot access local variable 'time' where it is not associated with a value
2025-07-29 14:16:50 - utils.error_handlers - ERROR - Unexpected Error: cannot access local variable 'time' where it is not associated with a value
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 332, in text_to_speech
    start_time = time.time()
                 ^^^^
UnboundLocalError: cannot access local variable 'time' where it is not associated with a value
2025-07-30 13:08:43 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 13:08:43 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 13:08:43 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 13:08:43 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 13:08:43 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 13:08:47 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 13:08:47 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 13:08:47 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 13:08:47 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 13:08:47 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 13:08:49 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 13:08:49 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 13:08:49 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 13:08:54 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 13:08:54 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 13:08:54 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 13:08:54 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 13:08:54 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 13:08:57 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 13:08:57 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 13:08:57 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 13:08:57 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 13:08:57 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 13:08:58 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 13:08:58 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 13:08:58 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:09:16 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:09:16 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:09:16 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:09:16 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:09:16 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:09:19 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:09:19 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:09:19 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:09:19 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:09:19 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:09:21 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:09:21 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:09:21 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:09:26 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:09:26 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:09:26 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:09:26 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:09:26 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:09:28 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:09:28 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:09:28 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:09:28 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:09:28 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:09:29 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:09:29 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:09:29 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:18:03 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:18:03 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:18:03 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:18:03 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:18:03 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:18:06 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:18:06 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:18:06 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:18:06 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:18:06 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:18:07 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:18:07 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:18:07 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:18:12 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:18:12 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:18:12 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:18:12 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:18:12 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:18:15 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:18:15 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:18:15 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:18:15 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:18:15 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:18:16 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:18:16 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:18:16 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:19:33 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:19:33 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:19:33 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:19:33 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:19:33 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:19:36 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:19:36 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:19:36 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:19:36 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:19:36 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:19:37 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:19:37 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:19:37 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:19:42 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:19:42 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:19:42 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:19:42 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:19:42 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:19:45 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:19:45 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:19:45 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:19:45 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:19:45 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:19:46 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:19:46 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:19:46 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:22:05 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:22:05 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:22:05 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:22:05 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:22:05 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:22:07 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:22:07 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:22:07 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:22:07 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:22:07 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:22:09 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:22:09 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:22:09 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:22:21 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:22:21 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:22:21 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:22:21 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:22:21 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:22:24 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:22:24 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:22:24 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:22:24 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:22:24 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:22:25 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:22:25 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:22:25 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:22:25 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-30 15:22:37 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:22:37 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:22:37 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:22:37 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:22:37 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:22:39 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:22:39 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:22:39 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:22:39 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:22:39 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:22:41 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:22:41 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:22:41 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:22:41 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-30 15:23:09 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:23:09 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:23:09 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:23:09 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:23:09 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:23:11 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:23:11 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:23:11 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:23:11 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:23:11 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:23:13 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:23:13 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:23:13 - __main__ - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:23:13 - __main__ - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-30 15:23:18 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:23:18 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:23:18 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:23:18 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:23:18 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:23:36 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:23:36 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:23:36 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:23:36 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:23:36 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:23:38 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:23:38 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:23:38 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:23:38 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:23:38 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:23:49 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:23:49 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:23:49 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:23:49 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:23:49 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:23:51 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:23:51 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:23:51 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:23:51 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:23:51 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:23:53 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:23:53 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:23:53 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:23:53 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-30 15:23:59 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-30 15:23:59 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-30 15:23:59 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-30 15:23:59 - services.transcription_service - INFO - Using CPU for transcription
2025-07-30 15:23:59 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-30 15:24:01 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-30 15:24:01 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-30 15:24:01 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-30 15:24:01 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-30 15:24:01 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-30 15:24:02 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-30 15:24:02 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-30 15:24:02 - app - INFO - ToneBridge Backend initialized successfully
2025-07-30 15:24:02 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-30 15:24:07 - routes.api - INFO - Audio data decoded successfully: 42665 bytes, format: webm
2025-07-30 15:24:07 - utils.audio_utils - INFO - Loading audio: 42665 bytes, format: webm
2025-07-30 15:24:07 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-30 15:24:07 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpmtg0k44t.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpmtg0k44t.wav
2025-07-30 15:24:07 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-30 15:24:11 - utils.audio_utils - INFO - Audio loaded successfully: 42240 samples, 16000Hz
2025-07-30 15:24:12 - utils.audio_utils - INFO - Audio preprocessed: 8192 samples
2025-07-30 15:24:12 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-30 15:24:13 - services.transcription_service - INFO - Transcription completed: 'BOOM!' (5 characters)
2025-07-30 15:24:13 - services.transcription_service - INFO - Confidence: 0.7
2025-07-30 15:24:13 - services.transcription_service - INFO - Model used: whisper
2025-07-30 15:24:13 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-30 15:24:15 - services.emotion_service - INFO - Text emotion detected: surprise (confidence: 0.392)
2025-07-30 15:26:21 - routes.api - INFO - Audio data decoded successfully: 22379 bytes, format: webm
2025-07-30 15:26:21 - utils.audio_utils - INFO - Loading audio: 22379 bytes, format: webm
2025-07-30 15:26:21 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-30 15:26:21 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpbcu9iw3m.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpbcu9iw3m.wav
2025-07-30 15:26:21 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-30 15:26:21 - utils.audio_utils - INFO - Audio loaded successfully: 22080 samples, 16000Hz
2025-07-30 15:26:21 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-07-30 15:26:21 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-30 15:26:22 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-30 15:26:22 - services.transcription_service - INFO - Confidence: 0.5
2025-07-30 15:26:22 - services.transcription_service - INFO - Model used: whisper
2025-07-30 15:26:22 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-30 15:26:22 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-30 15:27:40 - routes.api - INFO - Audio data decoded successfully: 22379 bytes, format: webm
2025-07-30 15:27:40 - utils.audio_utils - INFO - Loading audio: 22379 bytes, format: webm
2025-07-30 15:27:40 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-30 15:27:40 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpmpmy_tih.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpmpmy_tih.wav
2025-07-30 15:27:41 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-30 15:27:41 - utils.audio_utils - INFO - Audio loaded successfully: 22080 samples, 16000Hz
2025-07-30 15:27:41 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-07-30 15:27:41 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-30 15:27:41 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-30 15:27:41 - services.transcription_service - INFO - Confidence: 0.5
2025-07-30 15:27:41 - services.transcription_service - INFO - Model used: whisper
2025-07-30 15:27:41 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-30 15:27:41 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-30 15:27:45 - routes.api - INFO - Audio data decoded successfully: 50393 bytes, format: webm
2025-07-30 15:27:45 - utils.audio_utils - INFO - Loading audio: 50393 bytes, format: webm
2025-07-30 15:27:45 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-30 15:27:45 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp93wd5h3w.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp93wd5h3w.wav
2025-07-30 15:27:45 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-30 15:27:45 - utils.audio_utils - INFO - Audio loaded successfully: 49920 samples, 16000Hz
2025-07-30 15:27:45 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-07-30 15:27:45 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-30 15:27:46 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-07-30 15:27:46 - services.transcription_service - INFO - Confidence: 0.5
2025-07-30 15:27:46 - services.transcription_service - INFO - Model used: whisper
2025-07-30 15:27:46 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-30 15:27:46 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-30 15:28:22 - routes.api - INFO - Audio data decoded successfully: 32170 bytes, format: webm
2025-07-30 15:28:22 - utils.audio_utils - INFO - Loading audio: 32170 bytes, format: webm
2025-07-30 15:28:22 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-30 15:28:22 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpe9zn2fvp.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpe9zn2fvp.wav
2025-07-30 15:28:22 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-30 15:28:22 - utils.audio_utils - INFO - Audio loaded successfully: 44160 samples, 16000Hz
2025-07-30 15:28:22 - utils.audio_utils - INFO - Audio preprocessed: 43136 samples
2025-07-30 15:28:22 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-30 15:28:23 - services.transcription_service - INFO - Transcription completed: 'Mm.' (3 characters)
2025-07-30 15:28:23 - services.transcription_service - INFO - Confidence: 0.5
2025-07-30 15:28:23 - services.transcription_service - INFO - Model used: whisper
2025-07-30 15:28:23 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-30 15:28:23 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-07-30 15:28:36 - routes.api - INFO - Audio data decoded successfully: 52619 bytes, format: webm
2025-07-30 15:28:36 - utils.audio_utils - INFO - Loading audio: 52619 bytes, format: webm
2025-07-30 15:28:36 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-30 15:28:36 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpbpgmdrqg.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpbpgmdrqg.wav
2025-07-30 15:28:36 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-30 15:28:36 - utils.audio_utils - INFO - Audio loaded successfully: 72960 samples, 16000Hz
2025-07-30 15:28:36 - utils.audio_utils - INFO - Audio preprocessed: 44032 samples
2025-07-30 15:28:36 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-30 15:28:37 - services.transcription_service - INFO - Transcription completed: 'Testing testing, this is a test and it better work.' (51 characters)
2025-07-30 15:28:37 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-07-30 15:28:37 - services.transcription_service - INFO - Model used: whisper
2025-07-30 15:28:37 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-30 15:28:37 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.490)
2025-07-31 11:34:14 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 11:34:14 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 11:34:14 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 11:34:14 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 11:34:14 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 11:34:18 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 11:34:18 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 11:34:18 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 11:34:18 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 11:34:18 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 11:34:21 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 11:34:21 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 11:34:21 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 11:34:21 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 11:34:26 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 11:34:26 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 11:34:26 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 11:34:26 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 11:34:26 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 11:34:28 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 11:34:28 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 11:34:28 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 11:34:28 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 11:34:28 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 11:34:30 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 11:34:30 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 11:34:30 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 11:34:30 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 11:34:38 - routes.api - INFO - Audio data decoded successfully: 5991 bytes, format: webm
2025-07-31 11:34:38 - utils.audio_utils - INFO - Loading audio: 5991 bytes, format: webm
2025-07-31 11:34:38 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-07-31 11:34:38 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpacer9tz4.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpacer9tz4.wav
2025-07-31 11:34:39 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-07-31 11:34:43 - utils.audio_utils - INFO - Audio loaded successfully: 7680 samples, 16000Hz
2025-07-31 11:34:44 - utils.audio_utils - INFO - Audio preprocessed: 3072 samples
2025-07-31 11:34:44 - services.transcription_service - INFO - Using Whisper for transcription
2025-07-31 11:34:45 - services.transcription_service - INFO - Transcription completed: 'mm' (2 characters)
2025-07-31 11:34:46 - services.transcription_service - INFO - Confidence: 0.5
2025-07-31 11:34:46 - services.transcription_service - INFO - Model used: whisper
2025-07-31 11:34:46 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-07-31 11:34:48 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.968)
2025-07-31 11:53:51 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 11:53:51 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 11:53:51 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 11:53:51 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 11:53:51 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 11:53:54 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 11:53:54 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 11:53:54 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 11:53:54 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 11:53:54 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 11:53:56 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 11:53:56 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 11:53:56 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 11:53:56 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 11:54:01 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 11:54:01 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 11:54:01 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 11:54:01 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 11:54:01 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 11:54:03 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 11:54:03 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 11:54:03 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 11:54:03 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 11:54:03 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 11:54:05 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 11:54:05 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 11:54:05 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 11:54:05 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 12:08:35 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 12:08:35 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 12:08:35 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 12:08:35 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 12:08:35 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 12:08:54 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 12:08:54 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 12:08:54 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 12:08:54 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 12:08:54 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 12:08:57 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 12:08:57 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 12:08:57 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 12:08:57 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 12:08:57 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 12:08:58 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 12:08:58 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 12:08:58 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 12:08:58 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 12:09:03 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 12:09:03 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 12:09:03 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 12:09:03 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 12:09:03 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 12:09:06 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 12:09:06 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 12:09:06 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 12:09:06 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 12:09:06 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 12:09:07 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 12:09:07 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 12:09:07 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 12:09:07 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 12:47:04 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 12:47:04 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 12:47:04 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 12:47:04 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 12:47:04 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 12:47:07 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 12:47:07 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 12:47:07 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 12:47:07 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 12:47:07 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 12:47:08 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 12:47:08 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 12:47:08 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 12:47:08 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 12:47:13 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 12:47:13 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 12:47:13 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 12:47:13 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 12:47:13 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 12:47:16 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 12:47:16 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 12:47:16 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 12:47:16 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 12:47:16 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 12:47:17 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 12:47:17 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 12:47:18 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 12:47:18 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 15:02:22 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 15:02:22 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 15:02:22 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 15:02:22 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 15:02:22 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 15:02:30 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 15:02:30 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 15:02:30 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 15:02:30 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 15:02:30 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 15:02:33 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 15:02:33 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 15:02:33 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 15:02:33 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-07-31 15:02:40 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-07-31 15:02:40 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-07-31 15:02:40 - services.transcription_service - INFO - transformers version: 4.35.0
2025-07-31 15:02:40 - services.transcription_service - INFO - Using CPU for transcription
2025-07-31 15:02:40 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-07-31 15:02:44 - services.transcription_service - INFO - Transcription models initialized successfully
2025-07-31 15:02:44 - services.transcription_service - INFO - Whisper pipeline created: True
2025-07-31 15:02:44 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-07-31 15:02:44 - services.emotion_service - INFO - Using CPU for emotion detection
2025-07-31 15:02:44 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-07-31 15:02:45 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-07-31 15:02:45 - services.emotion_service - INFO - Emotion pipeline created: True
2025-07-31 15:02:45 - app - INFO - ToneBridge Backend initialized successfully
2025-07-31 15:02:45 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-02 07:02:11 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-02 07:02:11 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-02 07:02:11 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-02 07:02:11 - services.transcription_service - INFO - Using CPU for transcription
2025-08-02 07:02:11 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-02 07:02:15 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-02 07:02:15 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-02 07:02:15 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-02 07:02:15 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-02 07:02:15 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-02 07:02:18 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-02 07:02:18 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-02 07:02:18 - app - INFO - ToneBridge Backend initialized successfully
2025-08-02 07:02:18 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-02 07:02:23 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-02 07:02:23 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-02 07:02:23 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-02 07:02:23 - services.transcription_service - INFO - Using CPU for transcription
2025-08-02 07:02:23 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-02 07:02:25 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-02 07:02:25 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-02 07:02:25 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-02 07:02:25 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-02 07:02:25 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-02 07:02:27 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-02 07:02:27 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-02 07:02:27 - app - INFO - ToneBridge Backend initialized successfully
2025-08-02 07:02:27 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-02 07:19:03 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-02 07:19:03 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-02 07:19:03 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-02 07:19:03 - services.transcription_service - INFO - Using CPU for transcription
2025-08-02 07:19:03 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-02 07:19:07 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-02 07:19:07 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-02 07:19:07 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-02 07:19:07 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-02 07:19:07 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-02 07:19:09 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-02 07:19:09 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-02 07:19:09 - app - INFO - ToneBridge Backend initialized successfully
2025-08-02 07:19:09 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-03 15:42:47 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-03 15:42:47 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-03 15:42:47 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-03 15:42:47 - services.transcription_service - INFO - Using CPU for transcription
2025-08-03 15:42:47 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-03 15:42:53 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-03 15:42:53 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-03 15:42:53 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-03 15:42:53 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-03 15:42:53 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-03 15:42:56 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-03 15:42:56 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-03 15:42:56 - app - INFO - ToneBridge Backend initialized successfully
2025-08-03 15:42:56 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-03 15:43:01 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-03 15:43:01 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-03 15:43:01 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-03 15:43:01 - services.transcription_service - INFO - Using CPU for transcription
2025-08-03 15:43:01 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-03 15:43:03 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-03 15:43:03 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-03 15:43:03 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-03 15:43:03 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-03 15:43:03 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-03 15:43:05 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-03 15:43:05 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-03 15:43:05 - app - INFO - ToneBridge Backend initialized successfully
2025-08-03 15:43:05 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-04 14:09:14 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 14:09:14 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 14:09:14 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 14:09:14 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 14:09:14 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 14:09:18 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 14:09:18 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 14:09:18 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 14:09:18 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 14:09:18 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 14:09:21 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 14:09:21 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 14:09:21 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 14:09:21 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-04 14:09:27 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 14:09:27 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 14:09:27 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 14:09:27 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 14:09:27 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 14:09:31 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 14:09:31 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 14:09:31 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 14:09:31 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 14:09:31 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 14:09:33 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 14:09:33 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 14:09:33 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 14:09:33 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100']
2025-08-04 14:09:41 - routes.api - INFO - Audio data decoded successfully: 35903 bytes, format: webm
2025-08-04 14:09:41 - utils.audio_utils - INFO - Loading audio: 35903 bytes, format: webm
2025-08-04 14:09:41 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:09:41 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpimq61895.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpimq61895.wav
2025-08-04 14:09:42 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:09:46 - utils.audio_utils - INFO - Audio loaded successfully: 35520 samples, 16000Hz
2025-08-04 14:09:48 - utils.audio_utils - INFO - Audio preprocessed: 2560 samples
2025-08-04 14:09:48 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:09:49 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-08-04 14:09:49 - services.transcription_service - INFO - Confidence: 0.5
2025-08-04 14:09:49 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:09:49 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:09:51 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-08-04 14:09:59 - routes.api - INFO - Audio data decoded successfully: 54257 bytes, format: webm
2025-08-04 14:09:59 - utils.audio_utils - INFO - Loading audio: 54257 bytes, format: webm
2025-08-04 14:09:59 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:09:59 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpk__4c26p.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpk__4c26p.wav
2025-08-04 14:09:59 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:09:59 - utils.audio_utils - INFO - Audio loaded successfully: 53760 samples, 16000Hz
2025-08-04 14:09:59 - utils.audio_utils - INFO - Audio preprocessed: 40448 samples
2025-08-04 14:09:59 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:10:00 - services.transcription_service - INFO - Transcription completed: 'Testing, testing.' (17 characters)
2025-08-04 14:10:00 - services.transcription_service - INFO - Confidence: 0.7
2025-08-04 14:10:00 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:10:00 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:10:00 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.953)
2025-08-04 14:12:56 - routes.api - INFO - Audio data decoded successfully: 175 bytes, format: webm
2025-08-04 14:12:56 - utils.audio_utils - INFO - Loading audio: 175 bytes, format: webm
2025-08-04 14:12:56 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:12:56 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpc68d2xk4.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpc68d2xk4.wav
2025-08-04 14:12:56 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:12:56 - utils.audio_utils - INFO - Audio loaded successfully: 960 samples, 16000Hz
2025-08-04 14:12:56 - utils.audio_utils - INFO - Audio preprocessed: 960 samples
2025-08-04 14:12:56 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:12:57 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-08-04 14:12:57 - services.transcription_service - INFO - Confidence: 0.5
2025-08-04 14:12:57 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:12:57 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:12:57 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-08-04 14:13:11 - routes.api - INFO - Audio data decoded successfully: 189 bytes, format: webm
2025-08-04 14:13:11 - utils.audio_utils - INFO - Loading audio: 189 bytes, format: webm
2025-08-04 14:13:11 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:13:11 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpyavvbaqy.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpyavvbaqy.wav
2025-08-04 14:13:11 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:13:11 - utils.audio_utils - INFO - Audio loaded successfully: 1920 samples, 16000Hz
2025-08-04 14:13:11 - utils.audio_utils - INFO - Audio preprocessed: 1920 samples
2025-08-04 14:13:11 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:13:12 - services.transcription_service - INFO - Transcription completed: 'you' (3 characters)
2025-08-04 14:13:12 - services.transcription_service - INFO - Confidence: 0.5
2025-08-04 14:13:12 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:13:12 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:13:12 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.965)
2025-08-04 14:13:20 - routes.api - INFO - Audio data decoded successfully: 10787 bytes, format: webm
2025-08-04 14:13:20 - utils.audio_utils - INFO - Loading audio: 10787 bytes, format: webm
2025-08-04 14:13:20 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:13:20 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpqazl8ar2.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpqazl8ar2.wav
2025-08-04 14:13:20 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:13:20 - utils.audio_utils - INFO - Audio loaded successfully: 10560 samples, 16000Hz
2025-08-04 14:13:20 - utils.audio_utils - INFO - Audio preprocessed: 4608 samples
2025-08-04 14:13:20 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:13:21 - services.transcription_service - INFO - Transcription completed: 'Thank you.' (10 characters)
2025-08-04 14:13:21 - services.transcription_service - INFO - Confidence: 0.7
2025-08-04 14:13:21 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:13:21 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:13:21 - services.emotion_service - INFO - Text emotion detected: happy (confidence: 0.990)
2025-08-04 14:14:13 - routes.api - ERROR - Transcription endpoint error: No audio data provided
2025-08-04 14:14:13 - utils.error_handlers - ERROR - ToneBridge Error: No audio data provided
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 90, in transcribe_audio
    raise ValidationError("No audio data provided")
utils.error_handlers.ValidationError: No audio data provided
2025-08-04 14:14:41 - routes.api - ERROR - Transcription endpoint error: No audio data provided
2025-08-04 14:14:41 - utils.error_handlers - ERROR - ToneBridge Error: No audio data provided
Traceback (most recent call last):
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alaqm\AppData\Roaming\Python\Python311\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\Projects\Personal Projects\Tone-Bridge\backend\routes\api.py", line 90, in transcribe_audio
    raise ValidationError("No audio data provided")
utils.error_handlers.ValidationError: No audio data provided
2025-08-04 14:14:57 - routes.api - INFO - Audio data decoded successfully: 27209 bytes, format: webm
2025-08-04 14:14:57 - utils.audio_utils - INFO - Loading audio: 27209 bytes, format: webm
2025-08-04 14:14:57 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:14:57 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmp83_282h7.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmp83_282h7.wav
2025-08-04 14:14:57 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:14:57 - utils.audio_utils - INFO - Audio loaded successfully: 26880 samples, 16000Hz
2025-08-04 14:14:57 - utils.audio_utils - INFO - Audio preprocessed: 16896 samples
2025-08-04 14:14:57 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:14:58 - services.transcription_service - INFO - Transcription completed: 'testing the website.' (20 characters)
2025-08-04 14:14:58 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-08-04 14:14:58 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:14:58 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:14:58 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.961)
2025-08-04 14:15:14 - routes.api - INFO - Audio data decoded successfully: 127673 bytes, format: webm
2025-08-04 14:15:14 - utils.audio_utils - INFO - Loading audio: 127673 bytes, format: webm
2025-08-04 14:15:14 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:15:14 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmps493pu7z.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmps493pu7z.wav
2025-08-04 14:15:14 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:15:14 - utils.audio_utils - INFO - Audio loaded successfully: 126720 samples, 16000Hz
2025-08-04 14:15:14 - utils.audio_utils - INFO - Audio preprocessed: 30208 samples
2025-08-04 14:15:14 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:15:15 - services.transcription_service - INFO - Transcription completed: 'Hello, testing the website.' (27 characters)
2025-08-04 14:15:15 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-08-04 14:15:15 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:15:15 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:15:15 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.968)
2025-08-04 14:15:26 - routes.api - INFO - Audio data decoded successfully: 50393 bytes, format: webm
2025-08-04 14:15:26 - utils.audio_utils - INFO - Loading audio: 50393 bytes, format: webm
2025-08-04 14:15:26 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:15:26 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpfpak2e6u.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpfpak2e6u.wav
2025-08-04 14:15:26 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:15:26 - utils.audio_utils - INFO - Audio loaded successfully: 49920 samples, 16000Hz
2025-08-04 14:15:26 - utils.audio_utils - INFO - Audio preprocessed: 25088 samples
2025-08-04 14:15:26 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:15:27 - services.transcription_service - INFO - Transcription completed: 'Hello, testing the web' (22 characters)
2025-08-04 14:15:27 - services.transcription_service - INFO - Confidence: 0.8999999999999999
2025-08-04 14:15:27 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:15:27 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:15:27 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.969)
2025-08-04 14:34:56 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 14:34:56 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 14:34:56 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 14:34:56 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 14:34:56 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 14:34:59 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 14:34:59 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 14:34:59 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 14:34:59 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 14:34:59 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 14:35:00 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 14:35:00 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 14:35:00 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 14:35:00 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:35:00 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 14:35:00 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:44:08 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 14:44:08 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 14:44:08 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 14:44:08 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 14:44:08 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 14:44:11 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 14:44:11 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 14:44:11 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 14:44:11 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 14:44:11 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 14:44:12 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 14:44:12 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 14:44:12 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 14:44:12 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:44:12 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 14:44:12 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:3000', 'http://localhost:8100', 'https://tonebridge.vercel.app', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:44:47 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 14:44:47 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 14:44:47 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 14:44:47 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 14:44:47 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 14:44:50 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 14:44:50 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 14:44:50 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 14:44:50 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 14:44:50 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 14:44:52 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 14:44:52 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 14:44:52 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 14:44:52 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:44:52 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 14:44:52 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:44:57 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 14:44:57 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 14:44:57 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 14:44:57 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 14:44:57 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 14:44:59 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 14:44:59 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 14:44:59 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 14:44:59 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 14:44:59 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 14:45:01 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 14:45:01 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 14:45:01 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 14:45:01 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:45:01 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 14:45:01 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 14:45:13 - routes.api - INFO - Audio data decoded successfully: 48461 bytes, format: webm
2025-08-04 14:45:13 - utils.audio_utils - INFO - Loading audio: 48461 bytes, format: webm
2025-08-04 14:45:13 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:45:13 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpeywcukas.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpeywcukas.wav
2025-08-04 14:45:13 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:45:16 - utils.audio_utils - INFO - Audio loaded successfully: 48000 samples, 16000Hz
2025-08-04 14:45:16 - utils.audio_utils - INFO - Audio preprocessed: 43520 samples
2025-08-04 14:45:16 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:45:17 - services.transcription_service - INFO - Transcription completed: 'Testing, testing, one, two, three, testing.' (43 characters)
2025-08-04 14:45:17 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-08-04 14:45:17 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:45:17 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:45:19 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-08-04 14:48:30 - routes.api - INFO - Audio data decoded successfully: 71175 bytes, format: webm
2025-08-04 14:48:30 - utils.audio_utils - INFO - Loading audio: 71175 bytes, format: webm
2025-08-04 14:48:30 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 14:48:30 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpybg3n_5g.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpybg3n_5g.wav
2025-08-04 14:48:31 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 14:48:31 - utils.audio_utils - INFO - Audio loaded successfully: 70080 samples, 16000Hz
2025-08-04 14:48:31 - utils.audio_utils - INFO - Audio preprocessed: 42496 samples
2025-08-04 14:48:31 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 14:48:31 - services.transcription_service - INFO - Transcription completed: 'Testing, testing, one, two, three, testing.' (43 characters)
2025-08-04 14:48:31 - services.transcription_service - INFO - Confidence: 0.7999999999999999
2025-08-04 14:48:31 - services.transcription_service - INFO - Model used: whisper
2025-08-04 14:48:31 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 14:48:32 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.962)
2025-08-04 15:04:13 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:04:13 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:04:13 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:04:13 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:04:13 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:04:16 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:04:16 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:04:16 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:04:16 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:04:16 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:04:17 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:04:17 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:04:17 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:04:17 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:04:17 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:04:17 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:06:46 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:06:46 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:06:46 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:06:46 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:06:46 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:06:48 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:06:48 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:06:48 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:06:48 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:06:48 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:06:50 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:06:50 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:06:50 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:06:50 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:06:50 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:06:50 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:06:55 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:06:55 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:06:55 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:06:55 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:06:55 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:06:58 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:06:58 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:06:58 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:06:58 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:06:58 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:06:59 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:06:59 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:06:59 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:06:59 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:06:59 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:06:59 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:07:55 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:07:55 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:07:55 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:07:55 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:07:55 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:07:58 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:07:58 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:07:58 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:07:58 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:07:58 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:07:59 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:07:59 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:07:59 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:07:59 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:07:59 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:07:59 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:08:05 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:08:05 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:08:05 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:08:05 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:08:05 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:08:08 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:08:08 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:08:08 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:08:08 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:08:08 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:08:09 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:08:09 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:08:09 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:08:09 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:08:09 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:08:09 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'https://localhost:8100', 'http://192.168.1.210:8100', 'https://192.168.1.210:8100', 'http://localhost:3000', 'https://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:08:32 - routes.api - INFO - Audio data decoded successfully: 49427 bytes, format: webm
2025-08-04 15:08:32 - utils.audio_utils - INFO - Loading audio: 49427 bytes, format: webm
2025-08-04 15:08:32 - utils.audio_utils - INFO - Converting webm to wav using ffmpeg...
2025-08-04 15:08:32 - utils.audio_utils - INFO - Running ffmpeg: ffmpeg -y -i C:\Users\alaqm\AppData\Local\Temp\tmpu2lo410s.webm -ar 16000 -ac 1 C:\Users\alaqm\AppData\Local\Temp\tmpu2lo410s.wav
2025-08-04 15:08:33 - utils.audio_utils - INFO - ffmpeg conversion completed successfully
2025-08-04 15:08:36 - utils.audio_utils - INFO - Audio loaded successfully: 48960 samples, 16000Hz
2025-08-04 15:08:36 - utils.audio_utils - INFO - Audio preprocessed: 40960 samples
2025-08-04 15:08:36 - services.transcription_service - INFO - Using Whisper for transcription
2025-08-04 15:08:37 - services.transcription_service - INFO - Transcription completed: 'Testing testing' (15 characters)
2025-08-04 15:08:37 - services.transcription_service - INFO - Confidence: 0.7
2025-08-04 15:08:37 - services.transcription_service - INFO - Model used: whisper
2025-08-04 15:08:37 - services.emotion_service - INFO - Using AI-based emotion detection (transformer model)
2025-08-04 15:08:39 - services.emotion_service - INFO - Text emotion detected: neutral (confidence: 0.963)
2025-08-04 15:10:01 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:10:01 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:10:01 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:10:01 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:10:01 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:10:04 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:10:04 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:10:04 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:10:04 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:10:04 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:10:06 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:10:06 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:10:06 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:10:06 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:10:06 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:10:06 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:10:33 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:10:33 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:10:33 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:10:33 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:10:33 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:10:35 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:10:35 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:10:35 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:10:35 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:10:35 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:10:37 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:10:37 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:10:37 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:10:37 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:10:37 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:10:37 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:10:57 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:10:57 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:10:57 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:10:57 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:10:57 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:10:59 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:10:59 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:10:59 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:10:59 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:10:59 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:11:00 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:11:00 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:11:00 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:11:00 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:11:00 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:11:00 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:21:42 - services.transcription_service - INFO - TRANSFORMERS_AVAILABLE: True
2025-08-04 15:21:42 - services.transcription_service - INFO - torch version: 2.7.1+cpu
2025-08-04 15:21:42 - services.transcription_service - INFO - transformers version: 4.35.0
2025-08-04 15:21:42 - services.transcription_service - INFO - Using CPU for transcription
2025-08-04 15:21:42 - services.transcription_service - INFO - Initializing Whisper pipeline with model: openai/whisper-base
2025-08-04 15:21:45 - services.transcription_service - INFO - Transcription models initialized successfully
2025-08-04 15:21:45 - services.transcription_service - INFO - Whisper pipeline created: True
2025-08-04 15:21:45 - services.emotion_service - INFO - TRANSFORMERS_AVAILABLE for emotion: True
2025-08-04 15:21:45 - services.emotion_service - INFO - Using CPU for emotion detection
2025-08-04 15:21:45 - services.emotion_service - INFO - Initializing emotion pipeline with model: SamLowe/roberta-base-go_emotions
2025-08-04 15:21:46 - services.emotion_service - INFO - Emotion detection models initialized successfully
2025-08-04 15:21:46 - services.emotion_service - INFO - Emotion pipeline created: True
2025-08-04 15:21:46 - app - INFO - Detected local IP: 192.168.1.210
2025-08-04 15:21:46 - app - INFO - Configured CORS origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
2025-08-04 15:21:46 - app - INFO - ToneBridge Backend initialized successfully
2025-08-04 15:21:46 - app - INFO - CORS allowed origins: ['http://localhost:3000', 'http://localhost:8100', 'https://localhost:8100', 'https://tonebridge.vercel.app', 'http://localhost:8100', 'http://192.168.1.210:8100', 'http://localhost:3000', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'http://192.168.1.100:3000', 'http://192.168.1.100:8100', 'https://192.168.1.100:3000', 'https://192.168.1.100:8100', 'http://10.0.0.1:3000', 'http://10.0.0.1:8100', 'https://10.0.0.1:3000', 'https://10.0.0.1:8100', 'http://192.168.1.210:3000', 'http://192.168.1.210:8100', 'https://192.168.1.210:3000', 'https://192.168.1.210:8100', 'capacitor://localhost', 'ionic://localhost', 'http://localhost', 'https://localhost']
